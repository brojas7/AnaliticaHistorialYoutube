{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8ff0ef39",
      "metadata": {
        "id": "8ff0ef39"
      },
      "source": [
        "\n",
        "# **Cuaderno de Proyecto — Ciencia de Datos con YouTube**\n",
        "**Curso:** SINT-200  \n",
        "**Profesor:** Dr. Tomás de Camino Beck  \n",
        "**Estudiante(s):** _Bernal Rojas Villalobos_  \n",
        "**Fecha de entrega:** 21 de Octubre\n",
        "\n",
        "---\n",
        "\n",
        "## Instrucciones Generales\n",
        "\n",
        "Reto: Exportar datos de tu actividad YouTube (Google Takeout), construir una matriz usuario-contenido con señales (vistas, likes, tiempo, etc.), hacer EDA de sesgos/“burbujas”, y entrenar dos recomendadores (colaborativo vs. basado en contenido). Comparar métricas (cosas como precision@k, recall@k, cobertura) y explicar errores.  \n",
        "\n",
        "\n",
        "\n",
        "Este cuaderno sirve como **especificación y entregable** del proyecto. Debes completar cada sección marcada con **TODO** y dejar celdas de código **ejecutables** y **reproducibles**. El reto tiene dos proyectos:\n",
        "\n",
        "1. **Proyecto 1 — Tu Huella YouTube: Recomendador y Análisis de Burbuja Algorítmica.**  \n",
        "2. **Proyecto 2 — Detección de “Doomscrolling”: Predicción de sesiones extendidas.**\n",
        "\n",
        "### Ética y Privacidad de Datos\n",
        "- Puedes **anonimizar** tu información de YouTube (IDs, títulos, canales, tiempos) antes de subirla aquí.  \n",
        "- Alternativamente, puedes usar datos de otra persona **con su consentimiento informado** y **anonimizados**.  \n",
        "- No incluyas PII (información personal identificable) ni material sensible.  \n",
        "- Incluye un **Anexo de Privacidad** explicando qué datos usaste, cómo los obtuviste y cómo los protegiste.\n",
        "\n",
        "### Entregables\n",
        "- Este **cuaderno de Colab** completo y ejecutable.  \n",
        "- Carpeta `data/` con **muestras** de los datos (o datos sintéticos/anonimizados).  \n",
        "- **Diccionario de datos** (descripción de campos, tipos, unidades, supuestos).  \n",
        "- **Resultados y visualizaciones** dentro del notebook.  \n",
        "- **Conclusiones** + **Recomendaciones** (acciones sugeridas) + **Limitaciones** + **Trabajo futuro**.\n",
        "- Repositorio con estructura mínima:  \n",
        "  ```\n",
        "  README.md\n",
        "  data/        # muestras o datos anonimizados\n",
        "  notebooks/   # este cuaderno\n",
        "  src/         # funciones reutilizables\n",
        "  reports/     # figuras / tablas clave\n",
        "  ```\n",
        "\n",
        "### Rúbrica (100 pts)\n",
        "- **Charter/Problema y utilidad (10 pts)**: objetivos claros, hipótesis, valor para el usuario.  \n",
        "- **Adquisición y calidad de datos (10 pts)**: trazabilidad, permisos, limpieza básica.  \n",
        "- **EDA y visualizaciones (20 pts)**: distribución, outliers, correlaciones, sesgos/segmentos.  \n",
        "- **Baselines y metodología (10 pts)**: definición de referencia simple y por qué.  \n",
        "- **Modelado (20 pts)**: al menos **2 enfoques** comparados, justificación.  \n",
        "- **Evaluación (15 pts)**: métricas adecuadas, validación (temporal cuando aplique), error analysis.  \n",
        "- **Reproducibilidad (5 pts)**: semillas, funciones, estructura clara.  \n",
        "- **Conclusiones & ética (10 pts)**: hallazgos accionables y reflexiones de privacidad/sesgo.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b975eb",
      "metadata": {
        "id": "e7b975eb"
      },
      "source": [
        "\n",
        "## 0. Preparación del entorno\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clonar tu repositorio\n",
        "!git clone https://github.com/brojas7/AnaliticaHistorialYoutube.git\n",
        "\n",
        "# Moverse al directorio del proyecto\n",
        "%cd AnaliticaHistorialYoutube\n",
        "\n",
        "# Instalar dependencias necesarias\n",
        "!pip -q install pandas numpy matplotlib scikit-learn textblob python-dateutil tqdm dateparser google-generativeai gensim kaleido==0.2.1"
      ],
      "metadata": {
        "id": "LFe1U4XL8UJA",
        "outputId": "3741b106-70f7-4aec-8027-cda4ff0c0856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LFe1U4XL8UJA",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AnaliticaHistorialYoutube'...\n",
            "remote: Enumerating objects: 752, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 752 (delta 30), reused 0 (delta 0), pack-reused 698 (from 3)\u001b[K\n",
            "Receiving objects: 100% (752/752), 61.97 MiB | 7.52 MiB/s, done.\n",
            "Resolving deltas: 100% (234/234), done.\n",
            "/content/AnaliticaHistorialYoutube\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "54899c40",
      "metadata": {
        "id": "54899c40",
        "outputId": "975a4cf5-f4db-4c36-de8b-3508c82c11b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entorno listo. Versión de pandas: 2.2.2\n"
          ]
        }
      ],
      "source": [
        "# Imports base y configuración\n",
        "import os, json, math, random, itertools, collections, gzip, re, string, time, zipfile, io, sys\n",
        "from datetime import datetime, timedelta\n",
        "from dateutil import parser as dateparser\n",
        "\n",
        "#Manipulacion de datos\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "#Word2Vec para embeding\n",
        "import gensim.downloader as api\n",
        "\n",
        "#ML y estadistica\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
        "    confusion_matrix, mean_absolute_error, mean_squared_error\n",
        ")\n",
        "from scipy.stats import entropy\n",
        "from scipy.stats import chi2_contingency, zscore\n",
        "\n",
        "#Visualizacion\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import plotly.colors as pc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#Utils personalizados\n",
        "sys.path.append('/content/AnaliticaHistorialYoutube/src')\n",
        "from youtube_utils import load_watch_history, anonymize_df, sessionize\n",
        "from proyect_utils import str_to_list, normalize_value, reverse_lookup, hash_value\n",
        "from gemini_utils import setup_gemini, enrich_videos_with_gemini\n",
        "\n",
        "\n",
        "# Reproducibilidad\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 120)\n",
        "pd.set_option(\"display.max_rows\", 200)\n",
        "\n",
        "print(\"Entorno listo. Versión de pandas:\", pd.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13d2a739",
      "metadata": {
        "id": "13d2a739"
      },
      "source": [
        "\n",
        "## 1. Anexo de Privacidad y Origen de Datos (obligatorio)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Fuentes de datos\n",
        "Los datos utilizados provienen del **historial personal de visualizaciones de YouTube**, exportado mediante **Google Takeout** (https://takeout.google.com/). Este archivo contiene información sobre los videos vistos, fechas, títulos, canales, URLs y metadatos básicos asociados con cada visualización.\n",
        "\n",
        "\n",
        "No se incluyeron datos personales identificables como nombre de cuenta, direcciones de correo electrónico, comentarios ni listas privadas.\n",
        "\n",
        "\n",
        "Adicionalmente, algunos campos derivados (category, subtopic, format, keywords) fueron generados o enriquecidos mediante el uso del modelo Gemini de Google AI, utilizando únicamente los títulos y metadatos de los videos como entrada, sin exponer información personal.\n",
        "\n",
        "No se incluyeron datos personales identificables como nombre de cuenta, direcciones de correo electrónico, comentarios ni listas privadas.\n",
        "\n",
        "---\n",
        "\n",
        "### 1.2. Obtención de datos\n",
        "El dataset fue obtenido mediante el proceso oficial de **Google Takeout**, que garantiza la **portabilidad y propiedad de los datos por parte del usuario**.  \n",
        "El procedimiento fue el siguiente:\n",
        "1. Exportar la información de \"Historial de YouTube\" en formato JSON.  \n",
        "2. Cargar los archivos en el entorno local y procesarlos con scripts propios en Python.  \n",
        "3. Anonimizar todas las columnas que contuvieran posibles identificadores.\n",
        "\n",
        "---\n",
        "\n",
        "### 1.3. Protección y anonimización de datos\n",
        "Para proteger la privacidad del usuario:\n",
        "- Se aplicó una función de **hash SHA-256 truncado** (12 caracteres) a los campos sensibles (`video_title`, `channel_title`, `url`, `category`, `subtopic`, `format`, `keywords`).  \n",
        "- Se generó un **diccionario de mapeo local (`hash_maps.json`)** que permite revertir los valores solo para análisis internos.  \n",
        "  Este archivo **no se subió al repositorio** ni se compartió públicamente.  \n",
        "- Todos los valores anonimizados son irreversibles sin acceso al mapa local.  \n",
        "- Los resultados y visualizaciones se realizaron únicamente sobre la versión anonimizada del dataset.\n",
        "\n",
        "---\n",
        "\n",
        "### 1.4. Almacenamiento y manejo de datos\n",
        "- Los archivos se almacenan en una carpeta `data/` con permisos locales restringidos.  \n",
        "- No se emplearon servicios en la nube ni compartición pública de datos brutos.  \n",
        "- Los notebooks (`.ipynb`) solo incluyen ejemplos representativos y datos sintéticos o anonimizados.  \n",
        "- Cualquier publicación o repositorio del proyecto contiene **únicamente la versión anonimizada** de los datos.\n",
        "\n",
        "---\n",
        "\n",
        "### 1.5. Consideraciones éticas\n",
        "- Se respetaron los principios de **minimización de datos** (usar solo lo necesario para el análisis).  \n",
        "- Se evitó la reconstrucción o inferencia de información personal a partir del contenido visualizado.  \n",
        "- El proyecto tiene un propósito educativo y analítico, no comercial.  \n",
        "- La metodología aplicada busca concientizar sobre la huella digital y los sesgos de recomendación, no sobre el consumo individual de la persona.\n",
        "\n",
        "---\n",
        "\n",
        "### 1.6. Limitaciones y buenas prácticas futuras\n",
        "- Aunque la anonimización reduce el riesgo de identificación, un atacante con acceso al mapeo privado podría revertir los datos.  \n",
        "- Se recomienda destruir o cifrar el archivo `hash_maps.json` tras completar el análisis.  \n",
        "- En escenarios colaborativos, cada participante debe aplicar su propio proceso de anonimización independiente.\n",
        "\n"
      ],
      "metadata": {
        "id": "cE3GmuFHhEG1"
      },
      "id": "cE3GmuFHhEG1"
    },
    {
      "cell_type": "markdown",
      "id": "191b4ac5",
      "metadata": {
        "id": "191b4ac5"
      },
      "source": [
        "\n",
        "## 2. Selección de Proyecto\n",
        "**Marca con una X**\n",
        "\n",
        "- [ x ] **Proyecto 1 — Recomendador YouTube & Burbuja Algorítmica**  \n",
        "- [ ] **Proyecto 2 — Detección de Doomscrolling (clasificación temporal)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b85beb5a",
      "metadata": {
        "id": "b85beb5a"
      },
      "source": [
        "\n",
        "## 3. Utilidades comunes para YouTube (ingesta y parsing)\n",
        "\n",
        "Para **Proyecto 1** y **Proyecto 2** puedes usar datos de **Google Takeout**:  \n",
        "- `watch-history.json` (o `watch-history.html` en exportaciones antiguas)  \n",
        "- `search-history.json` (opcional)  \n",
        "- `likes.csv` / `subscriptions.csv` (según disponibilidad)\n",
        "\n",
        "> **Nota:** Los formatos de Takeout pueden cambiar con el tiempo. Ajusta el parser según tu exportación.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Proyecto 1 — Tu Huella YouTube: Recomendador & Burbuja Algorítmica**\n",
        "\n",
        "### Objetivo\n",
        "1) Construir **dos recomendadores** con tus datos de visualización:  \n",
        "   - **Baseline de popularidad** (o popularidad por canal/categoría).  \n",
        "   - **Modelo basado en contenido** (TF‑IDF/embeddings por título/canal) **o** **colaborativo** (si tienes interacciones de múltiples usuarios/fuentes).  \n",
        "2) Medir **Precision@k, Recall@k y Coverage** (y *diversidad*) en un esquema **offline**.  \n",
        "3) Analizar posibles **sesgos o “burbujas”** (temas/canales dominantes por hora, día, duración).  \n",
        "\n",
        "### Requisitos mínimos\n",
        "- **EDA**: distribución de vistas por canal, hora del día, día de semana, duración de sesiones, *top‑k* temas.  \n",
        "- **Ingeniería de features** (ej.: tokenización títulos, lematización opcional, normalización de canales).  \n",
        "- **Comparación de al menos 2 enfoques** de recomendación.  \n",
        "- **Evaluación offline** con *train/test split temporal*.  \n",
        "- **Análisis de errores** y discusión de sesgos/limitaciones.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "MCKWvDjYzZMt"
      },
      "id": "MCKWvDjYzZMt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 4. Charter del Proyecto 1\n",
        "**Propósito del proyecto**\n",
        "\n",
        "El objetivo de este proyecto es analizar mi historial de actividad en YouTube para comprender mis patrones de consumo, la diversidad de los contenidos que consumo y cómo los algoritmos de recomendación podrían estar reforzando o limitando esa diversidad.\n",
        "Además, se busca comparar distintos tipos de recomendadores (popularidad, basado en contenido y modelo híbrido contextual) para entender cuál ofrece mejores resultados y menor sesgo.\n",
        "\n",
        "\n",
        "**Preguntas clave**\n",
        "\n",
        "* ¿Qué tipo de contenido consumo con mayor frecuencia (música, educación, entretenimiento, etc.)?\n",
        "\n",
        "* ¿Existen “burbujas temáticas” o concentración en pocos clusters de contenido?\n",
        "\n",
        "* ¿Cómo varían mis hábitos según la hora o el día?\n",
        "\n",
        "* ¿Qué tan diversos son mis contenidos a lo largo del tiempo? ¿Ha aumentado o disminuido la entropía temática?\n",
        "\n",
        "* ¿Qué tipo de recomendador (popularidad, contenido o híbrido) logra mejor equilibrio entre precisión, cobertura y diversidad?\n",
        "\n",
        "* ¿Se pueden detectar outliers o consumos atípicos que rompan mis patrones habituales?\n",
        "\n",
        "**Alcance y metodología**\n",
        "\n",
        "* Datos: Historial personal de YouTube exportado desde Google Takeout, incluyendo títulos, canales, categorías, timestamp y metadatos de interacción.\n",
        "\n",
        "* Preprocesamiento: Limpieza, anonimización, embedding semántico de texto y representación numérica de cada video, enriquesimiento del dataset con LLMs\n",
        "\n",
        "* Modelado:\n",
        "\n",
        "  * Baseline de popularidad (recomienda lo más visto).\n",
        "\n",
        "  * Modelo basado en contenido (similaridad de embeddings).\n",
        "\n",
        "  * Modelo híbrido contextual (combina texto, tiempo, canal y señales de interacción).\n",
        "\n",
        "  * Evaluación: Precision@10, Recall@10, Coverage, Diversity, ClusterDiversity y BubbleIndex.\n",
        "\n",
        "* Análisis adicional:\n",
        "\n",
        "  * Clustering temático (t-SNE + K-Means).\n",
        "  \n",
        "  * Detección de outliers (Isolation Forest).\n",
        "\n",
        "  * Análisis temporal y de hábitos (entropía, frecuencia por hora/día, evolución de consumo).\n",
        "\n",
        "**Utilidad e impacto**\n",
        "\n",
        "* Personal: Permite reconocer sesgos de consumo, rutinas de horario y temas que dominan mi tiempo de pantalla.\n",
        "\n",
        "* Analítica: Comparar el comportamiento del algoritmo real de YouTube con modelos explicables y reproducibles.\n",
        "\n",
        "* Ética y diseño: Entender cómo los sistemas de recomendación pueden reforzar burbujas informativas o fomentar diversidad.\n",
        "\n",
        "* Futuro: Base para un modelo de “recomendación consciente” que promueva variedad y equilibrio temático."
      ],
      "metadata": {
        "id": "h-DU0jS32-BT"
      },
      "id": "h-DU0jS32-BT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diccionario de datos\n",
        "\n",
        "Antes de iniciar, este"
      ],
      "metadata": {
        "id": "5MfMkqu_gcDo"
      },
      "id": "5MfMkqu_gcDo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Datos\n",
        "\n",
        "En esta sección se va a preparar el dataset base para trabajar este proyecto.\n",
        "Consta de los siguientes pasos:\n",
        "\n",
        "* Cargar datasets crudos exportados desde google takout\n",
        "  * Se carga historial de busqueda, reproducciones y suscripciones\n",
        "  * No se puede utilizar los archivos de ninteracciones como comentarios, likes, etc debido a que soy un ususario con poca interacción y estos vienen vacíos.\n",
        "* Limpieza de datos\n",
        "  * Remover palabras no relevantes del titulo como \"Has visto\" o \"Buscaste\"\n",
        "  * Corregir tipos de datos\n",
        "  * Renombrar columnas\n",
        "* Transformación de datos\n",
        "  * Crear variables derivadas de tiempo\n",
        "  * Join de datasets\n",
        "  * Crear variables de interacción\n",
        "  * Eliminar videos de anuncios (No me interesan para este analisis)\n",
        "  * Generar variables adicionales usando LLMs, a partir del titulo y canal\n",
        "  * Crear embedings usando Word2Vec\n"
      ],
      "metadata": {
        "id": "HWdMlR62MV5L"
      },
      "id": "HWdMlR62MV5L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Cargar datos\n",
        "Historial personal de YouTube exportado desde Google Takeout, incluyendo títulos, canales, categorías, timestamp y metadatos de interacción."
      ],
      "metadata": {
        "id": "4-9mHPVAxfsy"
      },
      "id": "4-9mHPVAxfsy"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "df_search = load_watch_history('data/historial-de-búsqueda.json')\n",
        "df_watch = load_watch_history('data/historial-de-reproducciones.json')\n",
        "df_suscipciones = pd.read_csv('data/suscripciones.csv')\n",
        "\n",
        "print(df_search.shape)\n",
        "print(df_watch.shape)\n",
        "print(\"Eventos:\", len(df_watch), \"Rango:\", df_watch['timestamp'].min(), \"->\", df_watch['timestamp'].max())"
      ],
      "metadata": {
        "id": "5r5EmCD1_lai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d58959f-f91e-4dc0-82eb-dd31a28aeaae"
      },
      "id": "5r5EmCD1_lai",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12090, 6)\n",
            "(36842, 6)\n",
            "Eventos: 36842 Rango: 2018-02-22 02:05:35.427000+00:00 -> 2025-10-18 01:02:57.606000+00:00\n",
            "CPU times: user 3min 25s, sys: 484 ms, total: 3min 25s\n",
            "Wall time: 3min 38s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Limpieza de datos\n",
        "Limpiar los 3 dataframes\n",
        "* Remover palabras no relevantes del titulo como \"Has visto\" o \"Buscaste\"\n",
        "* Corregir tipos de datos\n",
        "* Renombrar columnas"
      ],
      "metadata": {
        "id": "06F2n8I5AYCg"
      },
      "id": "06F2n8I5AYCg"
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia base\n",
        "df_watch_clean = df_watch.copy()\n",
        "\n",
        "# Limpieza del título (remover \"Has visto\")\n",
        "df_watch_clean['video_title'] = df_watch_clean['title'].str.replace(r'^Has visto\\s+', '', regex=True)\n",
        "\n",
        "# Convertir timestamps\n",
        "df_watch_clean['watched_at'] = pd.to_datetime(df_watch_clean['timestamp'], utc=True)"
      ],
      "metadata": {
        "id": "TmaXN-S2RwP8"
      },
      "id": "TmaXN-S2RwP8",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia base\n",
        "df_search_clean = df_search.copy()\n",
        "\n",
        "# Limpieza del título (remover \"Has visto\")\n",
        "df_search_clean['search_terms'] = df_search_clean['title'].str.replace('Buscaste', '').str.strip()\n",
        "\n",
        "# Convertir timestamps\n",
        "df_search_clean['timestamp'] = pd.to_datetime(df_search_clean['timestamp'], utc=True)"
      ],
      "metadata": {
        "id": "3tCn36a3BGbl"
      },
      "id": "3tCn36a3BGbl",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_suscripciones_clean = df_suscipciones.rename(columns={\n",
        "    \"Título del canal\": \"channel_title\",\n",
        "    \"URL del canal\": \"channel_url\",\n",
        "    \"ID del canal\": \"channel_id\"\n",
        "})"
      ],
      "metadata": {
        "id": "skX3yaDpBT0N"
      },
      "id": "skX3yaDpBT0N",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Transformación de datos\n",
        "* Crear variables derivadas del tiempo\n",
        "* Unir dataset\n",
        "* Crear variables de interacción\n",
        "* Eliminar videos de anuncios\n",
        "* Generar variables adicionales usando LLMs\n",
        "* Crear embedings de variables de texto\n",
        "* Anonimizar datos sensibles para el análisis\n"
      ],
      "metadata": {
        "id": "knPt9Sw0AdY9"
      },
      "id": "knPt9Sw0AdY9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3.1 Crear variables derivadas de tiempo"
      ],
      "metadata": {
        "id": "DT_QpcycovGm"
      },
      "id": "DT_QpcycovGm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables derivadas de tiempo\n",
        "df_watch_clean['weekday'] = df_watch_clean['watched_at'].dt.day_name()\n",
        "df_watch_clean['hour'] = df_watch_clean['watched_at'].dt.hour\n",
        "df_watch_clean['hour_group'] = pd.cut(df_watch_clean['hour'],\n",
        "                                      bins=[-1,6,12,18,24],\n",
        "                                      labels=['madrugada','mañana','tarde','noche'])"
      ],
      "metadata": {
        "id": "tL-L1G-vSoOl"
      },
      "id": "tL-L1G-vSoOl",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3.2 Join de datasets"
      ],
      "metadata": {
        "id": "9TIpiCYJFTTQ"
      },
      "id": "9TIpiCYJFTTQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Renombramos la columna 'channel' en el historial para igualarla con suscripciones\n",
        "df_watch_clean = df_watch_clean.rename(columns={'channel': 'channel_title'})\n",
        "\n",
        "df_main = df_watch_clean.merge(\n",
        "    df_suscripciones_clean[['channel_title', 'channel_id']],\n",
        "    on='channel_title',\n",
        "    how='left',\n",
        "    indicator=True\n",
        ")\n",
        "\n",
        "df_main['is_subscribed'] = (df_main['_merge'] == 'both').astype(int)\n",
        "df_main.drop(columns=['_merge'], inplace=True)"
      ],
      "metadata": {
        "id": "22JiJ2uNSxKL"
      },
      "id": "22JiJ2uNSxKL",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3.3 Crear variables de interacción"
      ],
      "metadata": {
        "id": "YNvmH7llFXp_"
      },
      "id": "YNvmH7llFXp_"
    },
    {
      "cell_type": "code",
      "source": [
        "df_main['interaction_score'] = 1.0\n",
        "df_main.loc[df_main['is_subscribed'] == 1, 'interaction_score'] += 0.5"
      ],
      "metadata": {
        "id": "jwkzhrJuTr-G"
      },
      "id": "jwkzhrJuTr-G",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3.4 Eliminar videos de anuncios"
      ],
      "metadata": {
        "id": "x5-QdfkYFeZI"
      },
      "id": "x5-QdfkYFeZI"
    },
    {
      "cell_type": "code",
      "source": [
        "mask_valid = df_main['channel_title'].notna() & ~df_main['video_title'].str.contains(\"anuncio\", case=False, na=False)\n",
        "df_main_clean = df_main[mask_valid].copy()"
      ],
      "metadata": {
        "id": "HNGK6UL0Z4kg"
      },
      "id": "HNGK6UL0Z4kg",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ads = df_main[~mask_valid]\n",
        "df_ads.to_csv(\"data/df_ads_removed.csv\", index=False)"
      ],
      "metadata": {
        "id": "Jj-IlvxaZ7WS"
      },
      "id": "Jj-IlvxaZ7WS",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3.5 Generar variables adicionales usando LLMs\n",
        "\n",
        "La técnica de enriquicimiento de variables consiste en utilizar Gemini como LLM para pasarle el titulodel video y el canal, a partir de esta información, debe generar como salida un archivo json con las siguientes variables:\n",
        "* category: Categoria a la que pertenece el video\n",
        "* subtopic: Subtemas o sub categorias relacionadas\n",
        "* format: Devuelve el formato de video (ej, tutorial, video musical, vlog, etc)\n",
        "* keywords: Un vector de palabras clave relacionadas\n",
        "\n",
        "El módulo gemini_utils.py consta de 2 funciones:\n",
        "* setup_gemini: Configura el entorno y la cuenta de trabjo\n",
        "* enrich_videos_with_gemini: Funcion principal, maneja lotes de 20 registros\n",
        "* classify_batch_with_gemini: Ejecuta el llamado a Gemini,\n",
        "\n",
        "----\n",
        "**⚠️ Precausión**\n",
        "Si estás replicando este notebook para analizar tus propios datos debes tener en consideración algunas cosas:\n",
        "* Revisa la cantidad de registros de tu dataset\n",
        "* EL API de Gemini gratis solo permite recibir 250 llamadas al día\n",
        "* Si tu datset supera esta cantidad de registros, puede incurrir en algún gasto o bien, deberás buscar una alternativa, como dividir el df en lotes y correrlos de manera diaria o generar varios proyectos con tokens individuales para cada lote (Esto permite correr el df completo de manera gratuita, pero deberás unir los dfs despúes)\n",
        "* Si tu df es grande, este proceso puede demorar **horas**\n",
        "\n",
        "\n",
        "El prompt que utiliza es el siguiente:\n",
        "\n",
        "      Analiza los siguientes {len(batch_df)} videos de YouTube.\n",
        "      Devuelve **únicamente** una lista JSON válida donde cada elemento corresponde a un video,\n",
        "      con las claves: \"category\", \"subtopic\", \"format\", \"keywords\" (lista corta).\n",
        "      No incluyas texto adicional ni explicaciones.\n",
        "      Videos:\n",
        "      {chr(10).join(pairs)}\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "POuBff83FgVk"
      },
      "id": "POuBff83FgVk"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Configurar Gemini\n",
        "API_KEY = \"AQUI-TU-API-KEY\" # CAMBIA POR TU PROPIA API KEY\n",
        "model = setup_gemini(API_KEY)\n",
        "\n",
        "# 2.\n",
        "df_procesar = df_main_clean.head(20) # A modo de ejemplo solo 20 registros, IMPORTANTE: eliminar .head(20) si estas analizando tus propios datos\n",
        "\n",
        "# 3. Enriquecer tu DataFrame\n",
        "df_enriched = enrich_videos_with_gemini(\n",
        "    df_procesar,\n",
        "    model,\n",
        "    batch_size=20\n",
        ")"
      ],
      "metadata": {
        "id": "xx_NewUTJrLI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "590b187c-375c-49df-cbce-211bb35c8da9"
      },
      "id": "xx_NewUTJrLI",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]WARNING:tornado.access:400 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 608.73ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error intento 1: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: API key not valid. Please pass a valid API key. → Reintentando en 1.6s...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 154.11ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error intento 2: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: API key not valid. Please pass a valid API key. → Reintentando en 2.0s...\n",
            "Falló el batch, devolviendo valores por defecto.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:05<00:00,  5.45s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Muestra de formato generado por Gemini\n",
        "df_enriched[[\"category\",\"subtopic\",\"format\",\"keywords\"]].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Itr7eEYug4_f",
        "outputId": "d4024ec7-5abd-437f-eb35-88d8b656f80d"
      },
      "id": "Itr7eEYug4_f",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  category subtopic       format keywords\n",
              "0    otros    otros  desconocido       []\n",
              "1    otros    otros  desconocido       []\n",
              "2    otros    otros  desconocido       []\n",
              "3    otros    otros  desconocido       []\n",
              "4    otros    otros  desconocido       []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29f1d312-28e7-4cd9-b995-ffb1a872fcc8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>subtopic</th>\n",
              "      <th>format</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>otros</td>\n",
              "      <td>otros</td>\n",
              "      <td>desconocido</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>otros</td>\n",
              "      <td>otros</td>\n",
              "      <td>desconocido</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>otros</td>\n",
              "      <td>otros</td>\n",
              "      <td>desconocido</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>otros</td>\n",
              "      <td>otros</td>\n",
              "      <td>desconocido</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>otros</td>\n",
              "      <td>otros</td>\n",
              "      <td>desconocido</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29f1d312-28e7-4cd9-b995-ffb1a872fcc8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29f1d312-28e7-4cd9-b995-ffb1a872fcc8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29f1d312-28e7-4cd9-b995-ffb1a872fcc8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-47b7f719-47dc-4811-9fb6-596bb1ca145e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47b7f719-47dc-4811-9fb6-596bb1ca145e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-47b7f719-47dc-4811-9fb6-596bb1ca145e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_enriched[[\\\"category\\\",\\\"subtopic\\\",\\\"format\\\",\\\"keywords\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"otros\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subtopic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"otros\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"format\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"desconocido\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Mi caso**\n",
        "Este proceso puede demorar muchas horas, por lo que para efectos de replicabilidad de este notebook **únicamente** si estas usando mis datos, procedemos a cargar a continuación el df resultante de este procesamiento en Gemini:\n",
        "\n",
        "Nota: Si estás replicando para tus propios datos, deberás ejecutar el paso anterior obligatoriamente"
      ],
      "metadata": {
        "id": "97HcpERJlGR_"
      },
      "id": "97HcpERJlGR_"
    },
    {
      "cell_type": "code",
      "source": [
        "df_main = pd.read_csv(\"data/df_enrich_enriquecido.csv\")\n",
        "print(df_main.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6FT1jvrWR9f",
        "outputId": "f5af37a8-61a3-4e70-b902-09af2d5e1a24"
      },
      "id": "p6FT1jvrWR9f",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31217, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3.6 Generar vectores de embedings usando word2vec\n",
        "\n",
        "Word2Vec es un modelo de embeddings entrenado por Google (Mikolov et al., 2013) que transforma palabras en vectores numéricos de alta dimensión (por defecto, 300 dimensiones).\n",
        "\n",
        "La idea central es:\n",
        "\n",
        "“Palabras que aparecen en contextos similares tienen representaciones vectoriales similares”.\n",
        "\n",
        "Por ejemplo, en el espacio de embeddings:\n",
        "\n",
        "    vector(\"king\") - vector(\"man\") + vector(\"woman\") ≈ vector(\"queen\")\n",
        "\n",
        "Para este caso usará **word2vec-google-news-300** que es una versión preentrenada de Word2Vec desarrollada por Google sobre un corpus de 100 mil millones de palabras de noticias.\n",
        "\n",
        "| Propiedad | Valor                                                         |\n",
        "| --------- | ------------------------------------------------------------- |\n",
        "| Dimensión | 300                                                           |\n",
        "| Palabras  | ~3 millones                                                   |\n",
        "| Idioma    | Inglés                                                        |\n",
        "| Fuente    | Google News                                                   |\n",
        "| Uso común | NLP clásico, similitud semántica, clustering, recomendaciones |\n"
      ],
      "metadata": {
        "id": "zwZJ1uoTo7IU"
      },
      "id": "zwZJ1uoTo7IU"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#Descargar modelo preentrenado\n",
        "model = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "id": "NJHhCmx4c_ZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86aa75de-8c25-4d01-c1ef-dc7a3cd7f31d"
      },
      "id": "NJHhCmx4c_ZV",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "CPU times: user 3min 31s, sys: 30.1 s, total: 4min 1s\n",
            "Wall time: 4min 35s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo con tu DataFrame\n",
        "df_main[\"keywords\"] = str_to_list(df_main[\"keywords\"])"
      ],
      "metadata": {
        "id": "UO_zpzRlpvbA"
      },
      "id": "UO_zpzRlpvbA",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_vector(text, model):\n",
        "    \"\"\"\n",
        "    Recibe un texto (text) y el modelo Word2Vec (model).\n",
        "    Si el texto es una cadena → lo convierte en una lista de palabras (tokens).\n",
        "    Busca cada palabra en el modelo Word2Vec.\n",
        "    Si la palabra existe en el vocabulario, obtiene su vector (300D).\n",
        "    Promedia todos los vectores válidos → eso representa el significado global del texto.\n",
        "    Si ninguna palabra existe, devuelve un vector de ceros\n",
        "    \"\"\"\n",
        "    if isinstance(text, list):\n",
        "        tokens = text\n",
        "    elif isinstance(text, str):\n",
        "        tokens = text.lower().split()\n",
        "    else:\n",
        "        tokens = []\n",
        "\n",
        "    valid_vectors = [model[w] for w in tokens if w in model]\n",
        "    if not valid_vectors:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(valid_vectors, axis=0)\n",
        "\n",
        "\n",
        "def get_keyword_vectors(keyword_list, model):\n",
        "    \"\"\"\n",
        "    Recibe una lista de keywords (por ejemplo [\"deep learning\", \"python\", \"tutorial\"]).\n",
        "    Para cada keyword:\n",
        "      Divide frases en palabras (e.g. \"deep learning\" → [\"deep\", \"learning\"]).\n",
        "      Busca cada palabra en el modelo\n",
        "      Si existen, obtiene sus vectores.\n",
        "      Promedia los vectores de las palabras de la frase.\n",
        "      Devuelve una lista de vectores 300D (uno por keyword).\n",
        "    \"\"\"\n",
        "    vectors = []\n",
        "    if not isinstance(keyword_list, list):\n",
        "        return []\n",
        "\n",
        "    for kw in keyword_list:\n",
        "        if not isinstance(kw, str):\n",
        "            continue\n",
        "\n",
        "        tokens = kw.split()  # divide frases tipo \"easy to learn\"\n",
        "        token_vectors = []\n",
        "\n",
        "        for token in tokens:\n",
        "            # Buscar distintas capitalizaciones\n",
        "            if token in model:\n",
        "                token_vectors.append(model[token])\n",
        "            elif token.capitalize() in model:\n",
        "                token_vectors.append(model[token.capitalize()])\n",
        "            elif token.upper() in model:\n",
        "                token_vectors.append(model[token.upper()])\n",
        "\n",
        "        # Promedia las palabras de la frase\n",
        "        if token_vectors:\n",
        "            vectors.append(np.mean(token_vectors, axis=0))\n",
        "        else:\n",
        "            vectors.append(np.zeros(model.vector_size))\n",
        "\n",
        "    return vectors"
      ],
      "metadata": {
        "id": "t5vngNEPdeC5"
      },
      "id": "t5vngNEPdeC5",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Generar embeddings por columna\n",
        "# ============================================================\n",
        "\n",
        "df_embed = df_main.copy()\n",
        "cols_single_vector = [\"category\", \"subtopic\", \"format\", \"video_title\", \"channel_title\"]\n",
        "\n",
        "print(\"Generando embeddings columna por columna...\")\n",
        "\n",
        "# Embeddings individuales (vector promedio 300D)\n",
        "for col in cols_single_vector:\n",
        "    print(f\"→ Procesando {col}\")\n",
        "    df_embed[f\"{col}_vec\"] = df_embed[col].apply(lambda x: get_text_vector(x, model))\n",
        "\n",
        "# Embeddings múltiples (lista de vectores 300D por keyword)\n",
        "print(\"→ Procesando keywords (lista de vectores)...\")\n",
        "df_embed[\"keywords_vec\"] = df_embed[\"keywords\"].apply(lambda x: get_keyword_vectors(x, model))\n",
        "\n",
        "print(\"Embeddings generados exitosamente.\")\n",
        "\n",
        "#Eliminar modelo para liberar memoria\n",
        "del model\n",
        "print(\"Memoria RAM liberada\")\n",
        "\n",
        "# ============================================================\n",
        "# Verificación de salida\n",
        "# ============================================================\n",
        "cols_to_show = [\n",
        "    \"keywords\",\n",
        "    \"category_vec\",\n",
        "    \"subtopic_vec\",\n",
        "    \"format_vec\",\n",
        "    \"video_title_vec\",\n",
        "    \"channel_title_vec\",\n",
        "    \"keywords_vec\"\n",
        "]\n",
        "\n",
        "print(\"\\n Ejemplo de salida:\")\n",
        "display(df_embed[cols_to_show].head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "s2QfOoTYu_4o",
        "outputId": "a44acaaf-b8b9-499c-ecc7-6f798cd15298"
      },
      "id": "s2QfOoTYu_4o",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando embeddings columna por columna...\n",
            "→ Procesando category\n",
            "→ Procesando subtopic\n",
            "→ Procesando format\n",
            "→ Procesando video_title\n",
            "→ Procesando channel_title\n",
            "→ Procesando keywords (lista de vectores)...\n",
            "Embeddings generados exitosamente.\n",
            "Memoria RAM liberada\n",
            "\n",
            " Ejemplo de salida:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            keywords  \\\n",
              "0               [piano, easy to learn, music lesson]   \n",
              "1        [Ed Sheeran, Perfect, piano tutorial, easy]   \n",
              "2    [proposal, love story, fairytale, relationship]   \n",
              "3         [pranks, friends, Valentine's Day, comedy]   \n",
              "4  [Morat, Yo Más Te Adoro, Latin Pop, Official M...   \n",
              "\n",
              "                                        category_vec  \\\n",
              "0  [0.13671875, -0.12109375, -0.100097656, -0.042...   \n",
              "1  [0.13671875, -0.12109375, -0.100097656, -0.042...   \n",
              "2  [0.035888672, -0.096191406, -0.21582031, -0.10...   \n",
              "3  [0.035888672, -0.096191406, -0.21582031, -0.10...   \n",
              "4  [0.03881836, -0.21679688, -0.053466797, 0.0388...   \n",
              "\n",
              "                                        subtopic_vec  \\\n",
              "0  [0.14831543, -0.08959961, 0.057739258, 0.00994...   \n",
              "1  [0.14831543, -0.08959961, 0.057739258, 0.00994...   \n",
              "2  [-0.020141602, -0.06933594, -0.03564453, 0.054...   \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "4  [0.014038086, -0.063964844, -0.0014648438, -0....   \n",
              "\n",
              "                                          format_vec  \\\n",
              "0  [0.13671875, -0.12109375, -0.100097656, -0.042...   \n",
              "1  [0.13671875, -0.12109375, -0.100097656, -0.042...   \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "3  [0.11779785, -0.052490234, 0.12548828, 0.09924...   \n",
              "4  [0.053019207, -0.10324097, -0.06339518, -0.006...   \n",
              "\n",
              "                                     video_title_vec  \\\n",
              "0  [-0.00730896, -0.015449524, 0.12197876, 0.0943...   \n",
              "1  [0.10127767, -0.012736003, -0.0616862, 0.04007...   \n",
              "2  [0.057807073, 0.0064154733, -0.017917208, 0.11...   \n",
              "3  [-0.014133453, -0.011779785, 0.123535156, 0.07...   \n",
              "4  [-0.032145184, 0.060221355, 0.13378906, 0.1557...   \n",
              "\n",
              "                                   channel_title_vec  \\\n",
              "0  [-0.100097656, -0.07861328, 0.07373047, 0.2656...   \n",
              "1  [0.12988281, 0.1875, -0.095214844, 0.4453125, ...   \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "3  [-0.08312988, -0.023071289, 0.20361328, 0.2065...   \n",
              "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                        keywords_vec  \n",
              "0  [[0.15917969, -0.17578125, -0.10449219, -0.066...  \n",
              "1  [[0.12915039, 0.3154297, -0.19726562, 0.077758...  \n",
              "2  [[-0.14355469, 0.025512695, 0.12011719, 0.0546...  \n",
              "3  [[0.18945312, 0.15039062, 0.10449219, 0.363281...  \n",
              "4  [[0.24414062, -0.030029297, -0.24023438, -0.33...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56a4b34a-9daa-43f6-8f30-19e0a724c61b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keywords</th>\n",
              "      <th>category_vec</th>\n",
              "      <th>subtopic_vec</th>\n",
              "      <th>format_vec</th>\n",
              "      <th>video_title_vec</th>\n",
              "      <th>channel_title_vec</th>\n",
              "      <th>keywords_vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[piano, easy to learn, music lesson]</td>\n",
              "      <td>[0.13671875, -0.12109375, -0.100097656, -0.042...</td>\n",
              "      <td>[0.14831543, -0.08959961, 0.057739258, 0.00994...</td>\n",
              "      <td>[0.13671875, -0.12109375, -0.100097656, -0.042...</td>\n",
              "      <td>[-0.00730896, -0.015449524, 0.12197876, 0.0943...</td>\n",
              "      <td>[-0.100097656, -0.07861328, 0.07373047, 0.2656...</td>\n",
              "      <td>[[0.15917969, -0.17578125, -0.10449219, -0.066...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Ed Sheeran, Perfect, piano tutorial, easy]</td>\n",
              "      <td>[0.13671875, -0.12109375, -0.100097656, -0.042...</td>\n",
              "      <td>[0.14831543, -0.08959961, 0.057739258, 0.00994...</td>\n",
              "      <td>[0.13671875, -0.12109375, -0.100097656, -0.042...</td>\n",
              "      <td>[0.10127767, -0.012736003, -0.0616862, 0.04007...</td>\n",
              "      <td>[0.12988281, 0.1875, -0.095214844, 0.4453125, ...</td>\n",
              "      <td>[[0.12915039, 0.3154297, -0.19726562, 0.077758...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[proposal, love story, fairytale, relationship]</td>\n",
              "      <td>[0.035888672, -0.096191406, -0.21582031, -0.10...</td>\n",
              "      <td>[-0.020141602, -0.06933594, -0.03564453, 0.054...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.057807073, 0.0064154733, -0.017917208, 0.11...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[[-0.14355469, 0.025512695, 0.12011719, 0.0546...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[pranks, friends, Valentine's Day, comedy]</td>\n",
              "      <td>[0.035888672, -0.096191406, -0.21582031, -0.10...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.11779785, -0.052490234, 0.12548828, 0.09924...</td>\n",
              "      <td>[-0.014133453, -0.011779785, 0.123535156, 0.07...</td>\n",
              "      <td>[-0.08312988, -0.023071289, 0.20361328, 0.2065...</td>\n",
              "      <td>[[0.18945312, 0.15039062, 0.10449219, 0.363281...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Morat, Yo Más Te Adoro, Latin Pop, Official M...</td>\n",
              "      <td>[0.03881836, -0.21679688, -0.053466797, 0.0388...</td>\n",
              "      <td>[0.014038086, -0.063964844, -0.0014648438, -0....</td>\n",
              "      <td>[0.053019207, -0.10324097, -0.06339518, -0.006...</td>\n",
              "      <td>[-0.032145184, 0.060221355, 0.13378906, 0.1557...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[[0.24414062, -0.030029297, -0.24023438, -0.33...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56a4b34a-9daa-43f6-8f30-19e0a724c61b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-56a4b34a-9daa-43f6-8f30-19e0a724c61b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-56a4b34a-9daa-43f6-8f30-19e0a724c61b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d2f002dd-7e00-4525-a25b-8f6b2b7413bb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2f002dd-7e00-4525-a25b-8f6b2b7413bb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d2f002dd-7e00-4525-a25b-8f6b2b7413bb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_embed[cols_to_show]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category_vec\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subtopic_vec\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"format_vec\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_title_vec\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"channel_title_vec\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords_vec\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_global_embedding(row, weight_keywords=2.0):\n",
        "    \"\"\"\n",
        "    Inicializa una lista vectors para acumular los embeddings.\n",
        "    Recorre las columnas simples (category_vec, subtopic_vec, format_vec, video_title_vec, channel_title_vec) y agrega sus vectores válidos.\n",
        "    Calcula el promedio de los vectores en keywords_vec (si existen) y lo multiplica por weight_keywords (por defecto 2.0) → se le da más peso a las palabras clave.\n",
        "    Si no hay ningún vector válido, devuelve un vector de ceros (300D).\n",
        "    Promedia todos los vectores acumulados → obtiene el embedding global del video.\n",
        "    Se aplica a cada fila del DataFrame:\n",
        "    \"\"\"\n",
        "    vectors = []\n",
        "\n",
        "    # columnas simples\n",
        "    for col in [\"category_vec\", \"subtopic_vec\", \"format_vec\", \"video_title_vec\", \"channel_title_vec\"]:\n",
        "        if isinstance(row[col], np.ndarray) and row[col].any():\n",
        "            vectors.append(row[col])\n",
        "\n",
        "    # keywords (lista de vectores)\n",
        "    if isinstance(row[\"keywords_vec\"], list) and len(row[\"keywords_vec\"]) > 0:\n",
        "        kw_mean = np.mean(row[\"keywords_vec\"], axis=0)\n",
        "        vectors.append(kw_mean * weight_keywords)  # ponderamos keywords un poco más\n",
        "\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros(300)\n",
        "\n",
        "    # promedio de todos los embeddings\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "df_embed[\"content_vec\"] = df_embed.apply(lambda r: get_global_embedding(r), axis=1)\n",
        "\n",
        "print(\"Embeddings globales creados:\", df_embed[\"content_vec\"].iloc[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTlnVGELQFSu",
        "outputId": "f16eb110-2d68-46bc-8fac-f0d3fde78d32"
      },
      "id": "wTlnVGELQFSu",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings globales creados: (300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3.7 Anonimizar datos sensibles para el análisis\n"
      ],
      "metadata": {
        "id": "vBmc0TUmEpWB"
      },
      "id": "vBmc0TUmEpWB"
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_hash = [\n",
        "    \"title\",\n",
        "    \"channel_title\",\n",
        "    \"url\",\n",
        "    \"video_title\",\n",
        "    \"category\",\n",
        "    \"subtopic\",\n",
        "    \"format\",\n",
        "    \"keywords\"\n",
        "]\n",
        "\n",
        "hash_maps = {}\n",
        "\n",
        "for col in cols_to_hash:\n",
        "    if col in df_embed.columns:\n",
        "        print(f\"Anonimizando columna: {col}\")\n",
        "\n",
        "        # Normalizar todos los valores de la columna\n",
        "        df_embed[col] = df_embed[col].apply(normalize_value)\n",
        "\n",
        "        # Crear mapeo original → hash\n",
        "        uniques = df_embed[col].dropna().unique()\n",
        "        mapping = {val: hash_value(val) for val in uniques}\n",
        "        hash_maps[col] = mapping\n",
        "\n",
        "        # Aplicar los hashes\n",
        "        df_embed[col] = df_embed[col].map(mapping)\n",
        "    else:\n",
        "        print(f\"Columna '{col}' no encontrada en df_embed\")\n",
        "\n",
        "# Guardar los mapeos\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "with open(\"data/hash_maps.json\", \"w\") as f:\n",
        "    json.dump(hash_maps, f, indent=2)\n",
        "\n",
        "print(\"Anonimización completada\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0mHTU4MMLM9",
        "outputId": "9e83de67-4629-464b-907c-a0ea177d201c"
      },
      "id": "J0mHTU4MMLM9",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anonimizando columna: title\n",
            "Anonimizando columna: channel_title\n",
            "Anonimizando columna: url\n",
            "Anonimizando columna: video_title\n",
            "Anonimizando columna: category\n",
            "Anonimizando columna: subtopic\n",
            "Anonimizando columna: format\n",
            "Anonimizando columna: keywords\n",
            "Anonimización completada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ejemplo de como encontrar el valor\n",
        "reverse_lookup(\"category\", \"c26982b1425d\",hash_maps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "S_nmsnLJSUcW",
        "outputId": "aaff4d47-2ba7-4ca7-fbb1-4f4877638651"
      },
      "id": "S_nmsnLJSUcW",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'hash_maps' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3911343692.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Ejemplo de como encontrar el valor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreverse_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"c26982b1425d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/AnaliticaHistorialYoutube/src/proyect_utils.py\u001b[0m in \u001b[0;36mreverse_lookup\u001b[0;34m(column, hashed_value)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mBusca\u001b[0m \u001b[0men\u001b[0m \u001b[0mel\u001b[0m \u001b[0mdiccionario\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \"\"\"\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mreverse_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhash_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreverse_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashed_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hash_maps' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Muestra de como se queda el resultado\n",
        "df_embed.sample()"
      ],
      "metadata": {
        "id": "Pk6ysq-NQ4XT"
      },
      "id": "Pk6ysq-NQ4XT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 6. EDA\n",
        "\n",
        "En esta sección se analizan los patrones principales del dataset `df_embed`:\n",
        "- Distribución de videos por canal y categoría.\n",
        "- Frecuencia temporal (horas y días).\n",
        "- Señales de interacción (suscripción, score).\n",
        "- Correlaciones entre duración, interacción y popularidad (si aplica).\n",
        "- Posibles sesgos de exposición o segmentación temática"
      ],
      "metadata": {
        "id": "_vVabzzFDiZ-"
      },
      "id": "_vVabzzFDiZ-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.1 Resumen de datos"
      ],
      "metadata": {
        "id": "5F1GPcWkzLEC"
      },
      "id": "5F1GPcWkzLEC"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Resumen general de datos\n",
        "# ============================================================\n",
        "print(\"Número total de registros:\", len(df_embed))\n",
        "print(\"Período temporal:\", df_embed[\"timestamp\"].min(), \"→\", df_embed[\"timestamp\"].max())\n",
        "print(\"\\nColumnas principales:\\n\", df_embed.columns.tolist())\n",
        "print(df_embed.info())"
      ],
      "metadata": {
        "id": "QAlvd1MSKUGF"
      },
      "id": "QAlvd1MSKUGF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2 Evolución temporal de uso de Youtube"
      ],
      "metadata": {
        "id": "8w_6hX0EzSO2"
      },
      "id": "8w_6hX0EzSO2"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Evolución temporal del uso de YouTube (por mes y año)\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Aseguramos formato datetime\n",
        "df_embed[\"timestamp\"] = pd.to_datetime(df_embed[\"timestamp\"], errors=\"coerce\")\n",
        "\n",
        "# Agrupamos por año y mes\n",
        "df_usage = (\n",
        "    df_embed\n",
        "    .assign(period=df_embed[\"timestamp\"].dt.to_period(\"M\").astype(str))\n",
        "    .groupby(\"period\")\n",
        "    .size()\n",
        "    .reset_index(name=\"views\")\n",
        ")\n",
        "\n",
        "# Convertimos a datetime para graficar correctamente\n",
        "df_usage[\"period\"] = pd.to_datetime(df_usage[\"period\"])\n",
        "\n",
        "# Gráfico de evolución temporal\n",
        "fig = px.line(\n",
        "    df_usage,\n",
        "    x=\"period\",\n",
        "    y=\"views\",\n",
        "    markers=True,\n",
        "    title=\"Evolución mensual del uso de YouTube (número de videos vistos)\",\n",
        "    labels={\"period\": \"Mes\", \"views\": \"Videos vistos\"},\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    template=\"plotly_white\",\n",
        "    width=950, height=500,\n",
        "    xaxis_title=\"Mes y Año\",\n",
        "    yaxis_title=\"Cantidad de visualizaciones\",\n",
        "    hovermode=\"x unified\"\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_sD445XLZ9Wb"
      },
      "id": "_sD445XLZ9Wb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3 Distribuciones\n",
        "Al ser datos categoricos no es posible hacer histogramas, así que se realiza por conteo de frecuencias de aparición de cada categoría. Se exploran las siguientes variables:\n",
        "* Por canal\n",
        "* Por categoría\n",
        "* Por tema"
      ],
      "metadata": {
        "id": "Kr_39_p-zXRj"
      },
      "id": "Kr_39_p-zXRj"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Distribución por canal\n",
        "# ============================================================\n",
        "import plotly.express as px\n",
        "\n",
        "# Contar las vistas por canal\n",
        "top_channels = (\n",
        "    df_embed[\"channel_title\"]\n",
        "    .value_counts()\n",
        "    .head(15)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Renombrar las columnas de forma flexible\n",
        "top_channels.columns = [\"channel_title\", \"views\"]\n",
        "\n",
        "fig = px.bar(\n",
        "    top_channels,\n",
        "    x=\"channel_title\",\n",
        "    y=\"views\",\n",
        "    title=\"Top 15 canales más vistos\",\n",
        "    text_auto=True,\n",
        "    color=\"views\",\n",
        "    color_continuous_scale=\"Blues\"\n",
        ")\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Canal\",\n",
        "    yaxis_title=\"Número de vistas\",\n",
        "    template=\"plotly_white\",\n",
        "    xaxis_tickangle=45\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "8PSw7DoNKLg8"
      },
      "id": "8PSw7DoNKLg8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Distribución por categoría y subtema\n",
        "# ============================================================\n",
        "cat_counts = df_embed[\"category\"].value_counts().head(10)\n",
        "sub_counts = df_embed[\"subtopic\"].value_counts().head(10)\n",
        "\n",
        "fig1 = px.bar(\n",
        "    x=cat_counts.index, y=cat_counts.values,\n",
        "    title=\"Categorías más frecuentes\", color=cat_counts.values,\n",
        "    color_continuous_scale=\"Viridis\"\n",
        ")\n",
        "fig2 = px.bar(\n",
        "    x=sub_counts.index, y=sub_counts.values,\n",
        "    title=\"Subtemas más frecuentes\", color=sub_counts.values,\n",
        "    color_continuous_scale=\"Magma\"\n",
        ")\n",
        "\n",
        "fig1.update_layout(template=\"plotly_white\")\n",
        "fig2.update_layout(template=\"plotly_white\")\n",
        "fig1.show()\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "oBxVPgs3KNrs"
      },
      "id": "oBxVPgs3KNrs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.4 Análisis temporal"
      ],
      "metadata": {
        "id": "ZHq-8Dqm3s1L"
      },
      "id": "ZHq-8Dqm3s1L"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Mapa de calor hora x día\n",
        "# ============================================================\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Asegurar formato correcto de hora y día\n",
        "df_embed[\"hour\"] = pd.to_numeric(df_embed[\"hour\"], errors=\"coerce\")\n",
        "df_embed[\"weekday\"] = pd.Categorical(\n",
        "    df_embed[\"weekday\"],\n",
        "    categories=[\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"],\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "# Agrupar por día y hora\n",
        "heatmap_data = (\n",
        "    df_embed\n",
        "    .groupby([\"weekday\", \"hour\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"views\")\n",
        ")\n",
        "\n",
        "# Visualización: mapa de calor\n",
        "fig = px.density_heatmap(\n",
        "    heatmap_data,\n",
        "    x=\"hour\",\n",
        "    y=\"weekday\",\n",
        "    z=\"views\",\n",
        "    color_continuous_scale=\"Turbo\",\n",
        "    title=\"Mapa de calor — Actividad por día y hora\",\n",
        "    nbinsx=24\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    template=\"plotly_white\",\n",
        "    xaxis_title=\"Hora del día\",\n",
        "    yaxis_title=\"Día de la semana\",\n",
        "    width=950,\n",
        "    height=500\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_tOStrYVNrYw"
      },
      "id": "_tOStrYVNrYw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.5 Correlaciones categóricas con Cramér’s V"
      ],
      "metadata": {
        "id": "jHJhlEpM4Ra2"
      },
      "id": "jHJhlEpM4Ra2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para calcular Cramér’s V\n",
        "def cramers_v(x, y):\n",
        "    confusion = pd.crosstab(x, y)\n",
        "    chi2 = chi2_contingency(confusion)[0]\n",
        "    n = confusion.sum().sum()\n",
        "    phi2 = chi2 / n\n",
        "    r, k = confusion.shape\n",
        "    phi2corr = max(0, phi2 - ((k-1)*(r-1)) / (n-1))\n",
        "    rcorr = r - ((r-1)**2) / (n-1)\n",
        "    kcorr = k - ((k-1)**2) / (n-1)\n",
        "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
        "\n",
        "# Seleccionar variables categóricas relevantes\n",
        "cat_vars = [\"category\", \"subtopic\", \"format\", \"hour_group\", \"weekday\", \"is_subscribed\"]\n",
        "\n",
        "# Calcular matriz de Cramér’s V\n",
        "matrix = pd.DataFrame(index=cat_vars, columns=cat_vars, dtype=float)\n",
        "for var1 in cat_vars:\n",
        "    for var2 in cat_vars:\n",
        "        try:\n",
        "            matrix.loc[var1, var2] = cramers_v(df_embed[var1].astype(str), df_embed[var2].astype(str))\n",
        "        except Exception:\n",
        "            matrix.loc[var1, var2] = np.nan\n",
        "\n",
        "# ============================================================\n",
        "# Visualización del heatmap\n",
        "# ============================================================\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(matrix.astype(float), annot=True, cmap=\"YlOrRd\", vmin=0, vmax=1)\n",
        "plt.title(\"Matriz de correlaciones categóricas (Cramér’s V)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mam-bQ9yPsLv"
      },
      "id": "Mam-bQ9yPsLv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.6 Identificación de segmentos\n",
        "\n",
        "Se hará mediante exploración del espacio de embeddings\n",
        "\n",
        "Con esta sección busco darme una idea de los grupos, como mi espacio es bastante grande, usaré una muestra de 3000 ejemplos para tratar de entender exploratoriamente como se comportan mis datos.\n",
        "\n",
        "* Se toma una muestra de 3000 ejemplos\n",
        "* Se aplica t-sne\n",
        "* Se aplica PCA"
      ],
      "metadata": {
        "id": "7LnK0F2l4daP"
      },
      "id": "7LnK0F2l4daP"
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Muestra y normalización\n",
        "# ------------------------------------------------------------\n",
        "max_points = 3000  # ajusta si tu dataset es grande\n",
        "df_tsne = df_embed.sample(min(len(df_embed), max_points), random_state=42).reset_index(drop=True)\n",
        "X = normalize(np.vstack(df_tsne[\"content_vec\"].values))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# t-SNE\n",
        "# ------------------------------------------------------------\n",
        "print(f\"Ejecutando t-SNE sobre {X.shape[0]} puntos...\")\n",
        "tsne = TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=40,\n",
        "    learning_rate=\"auto\",\n",
        "    init=\"random\",\n",
        "    random_state=42\n",
        ")\n",
        "tsne_result = tsne.fit_transform(X)\n",
        "df_tsne[\"tsne_1\"] = tsne_result[:, 0]\n",
        "df_tsne[\"tsne_2\"] = tsne_result[:, 1]\n",
        "print(\"t-SNE completado\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Visualización t-SNE\n",
        "# ------------------------------------------------------------\n",
        "fig = px.scatter(\n",
        "    df_tsne,\n",
        "    x=\"tsne_1\",\n",
        "    y=\"tsne_2\",\n",
        "    opacity=0.6,\n",
        "    title=\"Espacio t-SNE de los embeddings de contenido\",\n",
        "    hover_data=[\"video_title\", \"category\", \"channel_title\"]\n",
        ")\n",
        "fig.update_traces(marker=dict(size=5, color=\"steelblue\", opacity=0.7, line=dict(width=0)))\n",
        "fig.update_layout(\n",
        "    template=\"plotly_white\",\n",
        "    width=900,\n",
        "    height=650,\n",
        "    showlegend=False\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# PCA\n",
        "# ------------------------------------------------------------\n",
        "print(\"Ejecutando PCA\")\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "pca_result = pca.fit_transform(X)\n",
        "df_tsne[\"pca_1\"] = pca_result[:, 0]\n",
        "df_tsne[\"pca_2\"] = pca_result[:, 1]\n",
        "\n",
        "fig = px.scatter(\n",
        "    df_tsne,\n",
        "    x=\"pca_1\",\n",
        "    y=\"pca_2\",\n",
        "    opacity=0.6,\n",
        "    title=\"PCA de los embeddings de contenido\",\n",
        "    hover_data=[\"video_title\", \"category\", \"channel_title\"]\n",
        ")\n",
        "fig.update_traces(marker=dict(size=5, color=\"darkorange\", opacity=0.7, line=dict(width=0)))\n",
        "fig.update_layout(\n",
        "    template=\"plotly_white\",\n",
        "    width=900,\n",
        "    height=650,\n",
        "    showlegend=False\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "rp1RenYVQKXB"
      },
      "id": "rp1RenYVQKXB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Método del Codo (Elbow Method) — PCA vs t-SNE\n",
        "# ============================================================\n",
        "\n",
        "K_range = range(2, 15)\n",
        "inertia_pca, inertia_tsne = [], []\n",
        "\n",
        "X_pca = df_tsne[[\"pca_1\", \"pca_2\"]].values\n",
        "X_tsne = df_tsne[[\"tsne_1\", \"tsne_2\"]].values\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Calcular inercia para cada K\n",
        "# ------------------------------------------------------------\n",
        "print(\"Calculando inercia para PCA...\")\n",
        "for k in tqdm(K_range):\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    km.fit(X_pca)\n",
        "    inertia_pca.append(km.inertia_)\n",
        "\n",
        "print(\"\\nCalculando inercia para t-SNE...\")\n",
        "for k in tqdm(K_range):\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    km.fit(X_tsne)\n",
        "    inertia_tsne.append(km.inertia_)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Graficar el método del codo\n",
        "# ------------------------------------------------------------\n",
        "plt.figure(figsize=(9,5))\n",
        "plt.plot(K_range, np.array(inertia_pca)/max(inertia_pca), \"o-\", label=\"PCA (normalizado)\", color=\"dodgerblue\")\n",
        "plt.plot(K_range, np.array(inertia_tsne)/max(inertia_tsne), \"o-\", label=\"t-SNE (normalizado)\", color=\"darkorange\")\n",
        "plt.title(\"Método del Codo (inercia normalizada)\")\n",
        "plt.xlabel(\"Número de clusters (k)\")\n",
        "plt.ylabel(\"Inercia normalizada\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UqBrX12aS1zc"
      },
      "id": "UqBrX12aS1zc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Evaluación de cohesión: Gráfico de Silueta (PCA y t-SNE)\n",
        "# ============================================================\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# K-Means sobre PCA\n",
        "# ------------------------------------------------------------\n",
        "X_pca = df_tsne[[\"pca_1\", \"pca_2\"]].values\n",
        "k_pca = 8  # ajusta según tu número de temas o clusters esperados\n",
        "kmeans_pca = KMeans(n_clusters=k_pca, random_state=42, n_init=10)\n",
        "labels_pca = kmeans_pca.fit_predict(X_pca)\n",
        "\n",
        "silhouette_avg_pca = silhouette_score(X_pca, labels_pca)\n",
        "print(f\"Silhouette promedio (PCA): {silhouette_avg_pca:.3f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# K-Means sobre t-SNE\n",
        "# ------------------------------------------------------------\n",
        "X_tsne = df_tsne[[\"tsne_1\", \"tsne_2\"]].values\n",
        "k_tsne = 8\n",
        "kmeans_tsne = KMeans(n_clusters=k_tsne, random_state=42, n_init=10)\n",
        "labels_tsne = kmeans_tsne.fit_predict(X_tsne)\n",
        "\n",
        "silhouette_avg_tsne = silhouette_score(X_tsne, labels_tsne)\n",
        "print(f\"Silhouette promedio (t-SNE): {silhouette_avg_tsne:.3f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Función auxiliar para plotear silueta\n",
        "# ------------------------------------------------------------\n",
        "def plot_silhouette(X, labels, title):\n",
        "    n_clusters = len(np.unique(labels))\n",
        "    silhouette_vals = silhouette_samples(X, labels)\n",
        "    y_lower = 10\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "\n",
        "    for i in range(n_clusters):\n",
        "        cluster_vals = silhouette_vals[labels == i]\n",
        "        cluster_vals.sort()\n",
        "        size_cluster_i = cluster_vals.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "        color = plt.cm.tab10(i / n_clusters)\n",
        "        ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_vals, facecolor=color, edgecolor=color, alpha=0.7)\n",
        "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "        y_lower = y_upper + 10  # espacio entre clusters\n",
        "\n",
        "    ax.axvline(np.mean(silhouette_vals), color=\"red\", linestyle=\"--\", label=\"Promedio global\")\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Coeficiente de silueta\")\n",
        "    ax.set_ylabel(\"Cluster\")\n",
        "    ax.legend()\n",
        "    ax.set_xlim([-0.2, 1])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Visualizar siluetas para PCA y t-SNE\n",
        "# ------------------------------------------------------------\n",
        "plot_silhouette(X_pca, labels_pca, f\"Silueta PCA (k={k_pca}, score={silhouette_avg_pca:.3f})\")\n",
        "plot_silhouette(X_tsne, labels_tsne, f\"Silueta t-SNE (k={k_tsne}, score={silhouette_avg_tsne:.3f})\")"
      ],
      "metadata": {
        "id": "hc88DTvwSPhI"
      },
      "id": "hc88DTvwSPhI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Visualización enriquecida de clusters en PCA y t-SNE\n",
        "# ============================================================\n",
        "\n",
        "# Unimos la info original (video, categoría, subtopic) con los embeddings\n",
        "df_pca_vis = pd.DataFrame(X_pca, columns=[\"pca_1\", \"pca_2\"])\n",
        "df_pca_vis[\"cluster\"] = labels_pca\n",
        "df_pca_vis[[\"video_title\", \"category\", \"subtopic\"]] = df_embed[[\"video_title\", \"category\", \"subtopic\"]].iloc[:len(df_pca_vis)].values\n",
        "\n",
        "df_tsne_vis = pd.DataFrame(X_tsne, columns=[\"tsne_1\", \"tsne_2\"])\n",
        "df_tsne_vis[\"cluster\"] = labels_tsne\n",
        "df_tsne_vis[[\"video_title\", \"category\", \"subtopic\"]] = df_embed[[\"video_title\", \"category\", \"subtopic\"]].iloc[:len(df_tsne_vis)].values\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# PCA\n",
        "# ------------------------------------------------------------\n",
        "fig_pca = px.scatter(\n",
        "    df_pca_vis,\n",
        "    x=\"pca_1\", y=\"pca_2\",\n",
        "    color=\"cluster\",\n",
        "    hover_data={\n",
        "        \"video_title\": True,\n",
        "        \"category\": True,\n",
        "        \"subtopic\": True,\n",
        "        \"cluster\": True,\n",
        "        \"pca_1\": False, \"pca_2\": False\n",
        "    },\n",
        "    title=f\"Distribución de clusters en espacio PCA (k={k_pca}, silhouette={silhouette_avg_pca:.3f})\",\n",
        "    color_continuous_scale=\"Turbo\"\n",
        ")\n",
        "fig_pca.update_traces(\n",
        "    marker=dict(size=6, opacity=0.8, line=dict(width=0.3, color=\"white\")),\n",
        "    hovertemplate=\"<b>%{customdata[0]}</b><br>Categoría: %{customdata[1]}<br>Subtema: %{customdata[2]}<br>Cluster: %{customdata[3]}\"\n",
        ")\n",
        "fig_pca.update_layout(template=\"plotly_white\", width=900, height=600)\n",
        "fig_pca.show()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# t-SNE\n",
        "# ------------------------------------------------------------\n",
        "fig_tsne = px.scatter(\n",
        "    df_tsne_vis,\n",
        "    x=\"tsne_1\", y=\"tsne_2\",\n",
        "    color=\"cluster\",\n",
        "    hover_data={\n",
        "        \"video_title\": True,\n",
        "        \"category\": True,\n",
        "        \"subtopic\": True,\n",
        "        \"cluster\": True,\n",
        "        \"tsne_1\": False, \"tsne_2\": False\n",
        "    },\n",
        "    title=f\"Distribución de clusters en espacio t-SNE (k={k_tsne}, silhouette={silhouette_avg_tsne:.3f})\",\n",
        "    color_continuous_scale=\"Turbo\"\n",
        ")\n",
        "fig_tsne.update_traces(\n",
        "    marker=dict(size=6, opacity=0.8, line=dict(width=0.3, color=\"white\")),\n",
        "    hovertemplate=\"<b>%{customdata[0]}</b><br>Categoría: %{customdata[1]}<br>Subtema: %{customdata[2]}<br>Cluster: %{customdata[3]}\"\n",
        ")\n",
        "fig_tsne.update_layout(template=\"plotly_white\", width=900, height=600)\n",
        "fig_tsne.show()\n"
      ],
      "metadata": {
        "id": "7GOlB-6HTkp9"
      },
      "id": "7GOlB-6HTkp9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Heatmap: proporción de categorías por cluster\n",
        "# ============================================================\n",
        "\n",
        "def top3_categories_per_cluster(df, label_col=\"cluster\", cat_col=\"category\"):\n",
        "    \"\"\"Devuelve el top 3 de categorías más frecuentes por cluster.\"\"\"\n",
        "    summary = (\n",
        "        df.groupby(label_col)[cat_col]\n",
        "        .value_counts(normalize=True)\n",
        "        .rename(\"proportion\")\n",
        "        .reset_index()\n",
        "    )\n",
        "    # Top 3 por cluster\n",
        "    top3 = summary.groupby(label_col).head(3).reset_index(drop=True)\n",
        "    return top3\n",
        "\n",
        "# --- PCA ---\n",
        "df_pca_vis[\"category\"] = df_embed[\"category\"].iloc[:len(df_pca_vis)].values\n",
        "top3_pca = top3_categories_per_cluster(df_pca_vis)\n",
        "\n",
        "# --- t-SNE ---\n",
        "df_tsne_vis[\"category\"] = df_embed[\"category\"].iloc[:len(df_tsne_vis)].values\n",
        "top3_tsne = top3_categories_per_cluster(df_tsne_vis)\n",
        "\n",
        "\n",
        "def plot_heatmap(df, title):\n",
        "    # Crear tabla pivote (categoría vs cluster)\n",
        "    pivot = (\n",
        "        df.pivot(index=\"category\", columns=\"cluster\", values=\"proportion\")\n",
        "        .fillna(0)\n",
        "    )\n",
        "\n",
        "    # Ordenar columnas (clusters)\n",
        "    pivot = pivot.reindex(sorted(pivot.columns), axis=1)\n",
        "\n",
        "    # Crear heatmap interactivo\n",
        "    fig = px.imshow(\n",
        "        pivot,\n",
        "        color_continuous_scale=\"Turbo\",\n",
        "        title=title,\n",
        "        labels=dict(x=\"Cluster\", y=\"Categoría\", color=\"Proporción\"),\n",
        "        aspect=\"auto\"\n",
        "    )\n",
        "    fig.update_layout(\n",
        "        width=950, height=600, template=\"plotly_white\",\n",
        "        xaxis_title=\"Cluster\", yaxis_title=\"Categoría\"\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "# Visualizar nuevamente\n",
        "plot_heatmap(top3_pca, \"PCA — Top 3 categorías más representadas por cluster\")\n",
        "plot_heatmap(top3_tsne, \"t-SNE — Top 3 categorías más representadas por cluster\")\n"
      ],
      "metadata": {
        "id": "fCjtRP1cUxe4"
      },
      "id": "fCjtRP1cUxe4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.7 Detección de Outliers"
      ],
      "metadata": {
        "id": "9C1RLqSlWpUj"
      },
      "id": "9C1RLqSlWpUj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "El Z-score mide cuántas desviaciones estándar está un valor respecto a la media:\n",
        "\n",
        "Por qué se usa |z| > 3: Es un criterio clásico en estadística para detectar valores atípicos “muy extremos”."
      ],
      "metadata": {
        "id": "5g3X8gqmBxv-"
      },
      "id": "5g3X8gqmBxv-"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Outliers en el espacio T-SNE con Z-score\n",
        "# ============================================================\n",
        "\n",
        "# Boxplots de componentes principales\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
        "sns.boxplot(y=df_tsne[\"tsne_1\"], color=\"cornflowerblue\", ax=axes[0])\n",
        "sns.boxplot(y=df_tsne[\"tsne_2\"], color=\"lightcoral\", ax=axes[1])\n",
        "axes[0].set_title(\"tsne 1 — Distribución y outliers\")\n",
        "axes[1].set_title(\"tsne 2 — Distribución y outliers\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Cálculo de Z-scores para identificar outliers\n",
        "# ------------------------------------------------------------\n",
        "df_tsne[\"z_tsne1\"] = zscore(df_tsne[\"tsne_1\"])\n",
        "df_tsne[\"z_tsne2\"] = zscore(df_tsne[\"tsne_2\"])\n",
        "\n",
        "# Definir umbral (|z| > 3 es común)\n",
        "threshold = 3\n",
        "outliers = df_tsne[(abs(df_tsne[\"z_tsne1\"]) > threshold) | (abs(df_tsne[\"z_tsne2\"]) > threshold)]\n",
        "print(f\"Detectados {len(outliers)} outliers en el espacio PCA ({len(outliers)/len(df_tsne)*100:.2f}% del total)\")\n",
        "\n",
        "# Mostrar ejemplos\n",
        "display(outliers[[\"video_title\", \"category\", \"tsne_1\", \"tsne_2\"]].head(10))"
      ],
      "metadata": {
        "id": "Jk0-y7rvA1ID"
      },
      "id": "Jk0-y7rvA1ID",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pra que no existen patrones de anomlías importantes que se puedan detectar con un método clásico como Z-Score. Vamos a probar con Isolation forest, un método de ML más robusto:\n",
        "\n",
        "\n",
        "    El Isolation Forest  es un modelo basado en árboles de decisión diseñado para detectar anomalías.\n",
        "    A diferencia de otros métodos (como el z-score o el clustering), no modela la densidad de los datos ni la distancia entre puntos.\n",
        "    Su idea clave es:\n",
        "\n",
        "        “Las anomalías son más fáciles de aislar que los puntos normales.”"
      ],
      "metadata": {
        "id": "73KyQT08Cgfu"
      },
      "id": "73KyQT08Cgfu"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Detección de outliers con Isolation Forest sobre t-SNE\n",
        "# ============================================================\n",
        "# Prepara los datos del t-SNE\n",
        "X_tsne = df_tsne[[\"tsne_1\", \"tsne_2\"]].values\n",
        "\n",
        "# Entrenamiento del Isolation Forest\n",
        "iso = IsolationForest(\n",
        "    contamination=0.03,  # proporción esperada de outliers (3%)\n",
        "    n_estimators=200,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "df_tsne[\"iforest_score\"] = iso.fit_predict(X_tsne)\n",
        "df_tsne[\"anomaly_score\"] = iso.decision_function(X_tsne)\n",
        "\n",
        "# Filtrar outliers detectados (-1 = outlier)\n",
        "outliers_if = df_tsne[df_tsne[\"iforest_score\"] == -1]\n",
        "print(f\"Outliers detectados por Isolation Forest: {len(outliers_if)} / {len(df_tsne)} ({len(outliers_if)/len(df_tsne)*100:.2f}%)\")\n",
        "\n",
        "# ============================================================\n",
        "# 🔹 Visualización de outliers en el plano t-SNE\n",
        "# ============================================================\n",
        "fig = px.scatter(\n",
        "    df_tsne,\n",
        "    x=\"tsne_1\",\n",
        "    y=\"tsne_2\",\n",
        "    color=\"anomaly_score\",\n",
        "    color_continuous_scale=\"Inferno\",\n",
        "    title=\"Detección de Outliers con Isolation Forest (espacio t-SNE)\",\n",
        "    hover_data=[\"video_title\", \"category\"],\n",
        "    opacity=0.7\n",
        ")\n",
        "\n",
        "# Agregar los puntos marcados como anomalías\n",
        "fig.add_scatter(\n",
        "    x=outliers_if[\"tsne_1\"],\n",
        "    y=outliers_if[\"tsne_2\"],\n",
        "    mode=\"markers\",\n",
        "    marker=dict(size=8, color=\"cyan\", symbol=\"x\", line=dict(width=1, color=\"black\")),\n",
        "    name=\"Outliers detectados\"\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    template=\"plotly_white\",\n",
        "    width=950,\n",
        "    height=650,\n",
        "    showlegend=True\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "z9FvbnsMAq6L"
      },
      "id": "z9FvbnsMAq6L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Isolation Forest local (por cluster) — PCA y t-SNE\n",
        "# ============================================================\n",
        "\n",
        "# --- Aseguramos que df_pca_vis y df_tsne_vis tienen las columnas necesarias ---\n",
        "for df_vis in [df_pca_vis, df_tsne_vis]:\n",
        "    if \"channel_title\" not in df_vis.columns and \"channel_title\" in df_embed.columns:\n",
        "        df_vis[\"channel_title\"] = df_embed[\"channel_title\"].iloc[:len(df_vis)].values\n",
        "\n",
        "# --- Función para aplicar Isolation Forest por cluster ---\n",
        "def isolation_per_cluster(df, coord_cols, cluster_col=\"cluster\", contamination=0.05):\n",
        "    df_out = df.copy()\n",
        "    df_out[\"iforest_local\"] = 1\n",
        "    df_out[\"iforest_score\"] = np.nan\n",
        "\n",
        "    for c in sorted(df_out[cluster_col].unique()):\n",
        "        subset = df_out[df_out[cluster_col] == c]\n",
        "        if len(subset) < 10:\n",
        "            continue\n",
        "        X = subset[coord_cols].values\n",
        "        iso = IsolationForest(\n",
        "            contamination=contamination,\n",
        "            random_state=42,\n",
        "            n_estimators=200,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        scores = iso.fit_predict(X)\n",
        "        decision = iso.decision_function(X)\n",
        "        df_out.loc[subset.index, \"iforest_local\"] = scores\n",
        "        df_out.loc[subset.index, \"iforest_score\"] = decision\n",
        "    return df_out\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# PCA\n",
        "# ============================================================\n",
        "df_pca_iso = isolation_per_cluster(df_pca_vis, [\"pca_1\", \"pca_2\"], \"cluster\", contamination=0.05)\n",
        "outliers_pca = df_pca_iso[df_pca_iso[\"iforest_local\"] == -1]\n",
        "\n",
        "fig_pca = px.scatter(\n",
        "    df_pca_iso,\n",
        "    x=\"pca_1\", y=\"pca_2\",\n",
        "    color=\"cluster\",\n",
        "    opacity=0.55,\n",
        "    title=\"Outliers locales (Isolation Forest por cluster — PCA)\",\n",
        "    hover_data={\n",
        "        \"video_title\": True,\n",
        "        \"category\": True,\n",
        "        \"subtopic\": True,\n",
        "        \"channel_title\": True,\n",
        "        \"cluster\": True,\n",
        "        \"iforest_score\": True\n",
        "    },\n",
        "    color_continuous_scale=\"Turbo\"\n",
        ")\n",
        "\n",
        "# Outliers rojos con hover detallado\n",
        "fig_pca.add_scatter(\n",
        "    x=outliers_pca[\"pca_1\"],\n",
        "    y=outliers_pca[\"pca_2\"],\n",
        "    mode=\"markers\",\n",
        "    marker=dict(size=9, color=\"red\", symbol=\"x\", line=dict(width=1, color=\"black\")),\n",
        "    name=\"Outliers locales\",\n",
        "    text=outliers_pca.apply(lambda r: f\"<b>{r['video_title']}</b><br>\"\n",
        "                                      f\"Categoría: {r['category']}<br>\"\n",
        "                                      f\"Subtema: {r['subtopic']}<br>\"\n",
        "                                      f\"Canal: {r['channel_title']}<br>\"\n",
        "                                      f\"Cluster: {r['cluster']}<br>\"\n",
        "                                      f\"Score: {r['iforest_score']:.3f}\", axis=1),\n",
        "    hoverinfo=\"text\"\n",
        ")\n",
        "fig_pca.update_layout(template=\"plotly_white\", width=950, height=650)\n",
        "fig_pca.show()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# t-SNE\n",
        "# ============================================================\n",
        "df_tsne_iso = isolation_per_cluster(df_tsne_vis, [\"tsne_1\", \"tsne_2\"], \"cluster\", contamination=0.05)\n",
        "outliers_tsne = df_tsne_iso[df_tsne_iso[\"iforest_local\"] == -1]\n",
        "\n",
        "fig_tsne = px.scatter(\n",
        "    df_tsne_iso,\n",
        "    x=\"tsne_1\", y=\"tsne_2\",\n",
        "    color=\"cluster\",\n",
        "    opacity=0.55,\n",
        "    title=\"Outliers locales (Isolation Forest por cluster — t-SNE)\",\n",
        "    hover_data={\n",
        "        \"video_title\": True,\n",
        "        \"category\": True,\n",
        "        \"subtopic\": True,\n",
        "        \"channel_title\": True,\n",
        "        \"cluster\": True,\n",
        "        \"iforest_score\": True\n",
        "    },\n",
        "    color_continuous_scale=\"Turbo\"\n",
        ")\n",
        "\n",
        "fig_tsne.add_scatter(\n",
        "    x=outliers_tsne[\"tsne_1\"],\n",
        "    y=outliers_tsne[\"tsne_2\"],\n",
        "    mode=\"markers\",\n",
        "    marker=dict(size=9, color=\"red\", symbol=\"x\", line=dict(width=1, color=\"black\")),\n",
        "    name=\"Outliers locales\",\n",
        "    text=outliers_tsne.apply(lambda r: f\"<b>{r['video_title']}</b><br>\"\n",
        "                                      f\"Categoría: {r['category']}<br>\"\n",
        "                                      f\"Subtema: {r['subtopic']}<br>\"\n",
        "                                      f\"Canal: {r['channel_title']}<br>\"\n",
        "                                      f\"Cluster: {r['cluster']}<br>\"\n",
        "                                      f\"Score: {r['iforest_score']:.3f}\", axis=1),\n",
        "    hoverinfo=\"text\"\n",
        ")\n",
        "fig_tsne.update_layout(template=\"plotly_white\", width=950, height=650)\n",
        "fig_tsne.show()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Comparativa de porcentaje de outliers\n",
        "# ============================================================\n",
        "summary = pd.DataFrame({\n",
        "    \"Cluster\": sorted(df_tsne_iso[\"cluster\"].unique()),\n",
        "    \"Outliers_tSNE(%)\": [\n",
        "        (df_tsne_iso.query(\"cluster==@c\")[\"iforest_local\"] == -1).mean() * 100\n",
        "        for c in sorted(df_tsne_iso[\"cluster\"].unique())\n",
        "    ],\n",
        "    \"Outliers_PCA(%)\": [\n",
        "        (df_pca_iso.query(\"cluster==@c\")[\"iforest_local\"] == -1).mean() * 100\n",
        "        for c in sorted(df_pca_iso[\"cluster\"].unique())\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"Porcentaje de outliers detectados por cluster:\")\n",
        "display(summary)\n",
        "\n",
        "print(f\"t-SNE promedio: {summary['Outliers_tSNE(%)'].mean():.2f}%\")\n",
        "print(f\"PCA promedio: {summary['Outliers_PCA(%)'].mean():.2f}%\")"
      ],
      "metadata": {
        "id": "S8Zxr2N_WCCm"
      },
      "id": "S8Zxr2N_WCCm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "35c69ef9",
      "metadata": {
        "id": "35c69ef9"
      },
      "source": [
        "\n",
        "## 7. Partición temporal y definición de tareas\n",
        "* Split de datset en train y test\n",
        "* Definición de metricas a evaluar"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.1 Spli de dataset\n",
        "\n",
        "Se utilizará el tiempo como medida temporal, en un 80% para entreno y 20% para evaluar"
      ],
      "metadata": {
        "id": "__GlK6g7LiRG"
      },
      "id": "__GlK6g7LiRG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4c0a861",
      "metadata": {
        "id": "a4c0a861"
      },
      "outputs": [],
      "source": [
        "# Asegurar que timestamp es datetime\n",
        "df_embed[\"timestamp\"] = pd.to_datetime(df_embed[\"timestamp\"], errors=\"coerce\")\n",
        "\n",
        "# Verifica que la conversión haya funcionado\n",
        "print(df_embed[\"timestamp\"].dtypes)\n",
        "print(df_embed[\"timestamp\"].head())\n",
        "\n",
        "# Split temporal: por ejemplo, último 20% del tiempo como test\n",
        "cut_ts = df_embed['timestamp'].quantile(0.8)\n",
        "train = df_embed[df_embed['timestamp'] <= cut_ts].copy()\n",
        "test  = df_embed[df_embed['timestamp'] >  cut_ts].copy()\n",
        "\n",
        "print(\"train:\", train['timestamp'].min(), \"->\", train['timestamp'].max(), \"n=\", len(train))\n",
        "print(\"test :\", test['timestamp'].min(),  \"->\", test['timestamp'].max(),  \"n=\", len(test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.2 Definició  de métricas para modelos\n",
        "\n",
        "Este apartado describe las métricas utilizadas para evaluar los tres recomendadores desarrollados (Popularidad, Contenido y Híbrido). Incluye su interpretación conceptual y sus fórmulas en notación matemática LaTeX.\n",
        "\n",
        "---\n",
        "\n",
        "##### **Precision@K**\n",
        "**Qué mide:** Exactitud de las recomendaciones: qué proporción de los videos recomendados son realmente relevantes (vistos posteriormente por el usuario).\n",
        "\n",
        "$$\n",
        "\\text{Precision@K} = \\frac{|R \\cap T|}{K}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "- $R$ = conjunto de videos recomendados (Top-K)\n",
        "- $T$ = conjunto de videos realmente vistos (True Set)\n",
        "- $K$ = número de videos recomendados\n",
        "\n",
        "**Interpretación:**\n",
        "- Valores cercanos a 1 indican recomendaciones más precisas.\n",
        "- Ejemplo: $\\text{Precision@10} = 0.1$ → 1 de cada 10 videos recomendados fue efectivamente visto.\n",
        "\n",
        "---\n",
        "\n",
        "##### **Recall@K**\n",
        "**Qué mide:** Qué fracción de los videos realmente vistos fueron recuperados por el sistema dentro de las recomendaciones.\n",
        "\n",
        "$$\n",
        "\\text{Recall@K} = \\frac{|R \\cap T|}{|T|}\n",
        "$$\n",
        "\n",
        "**Interpretación:**\n",
        "- Evalúa la **capacidad de recuperación** del modelo.\n",
        "- Un valor alto significa que el sistema logra capturar la mayoría de los intereses reales del usuario.\n",
        "\n",
        "---\n",
        "\n",
        "##### **Coverage**\n",
        "**Qué mide:** Porcentaje del catálogo total de videos que aparece al menos una vez en las listas de recomendación.\n",
        "\n",
        "$$\n",
        "\\text{Coverage} = \\frac{|R_{unique}|}{|I_{total}|}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "- $R_{unique}$ = videos únicos recomendados por el modelo\n",
        "- $I_{total}$ = tamaño total del catálogo (número de videos en *train*)\n",
        "\n",
        "**Interpretación:**\n",
        "- Cuanto mayor sea el Coverage, mayor es la **variedad global** de recomendaciones.\n",
        "- Un Coverage bajo indica que el sistema repite siempre los mismos videos populares.\n",
        "\n",
        "---\n",
        "\n",
        "##### **Diversity**\n",
        "**Qué mide:** La diversidad semántica dentro de una lista de recomendaciones. Se basa en la similitud del coseno entre los embeddings de contenido de los videos.\n",
        "\n",
        "$$\n",
        "\\text{Diversity} = 1 - \\frac{1}{N} \\sum_{i<j} \\text{sim}_{\\text{coseno}}(v_i, v_j)\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "- $v_i, v_j$ son los vectores de contenido de los videos $i$ y $j$.\n",
        "- $\\text{sim}_{\\text{coseno}}$ mide la similitud entre embeddings.\n",
        "\n",
        "**Interpretación:**\n",
        "- Valores altos → recomendaciones variadas entre sí.\n",
        "- Valores bajos → recomendaciones muy parecidas (monotemáticas).\n",
        "\n",
        "---\n",
        "\n",
        "##### **ClusterDiversity**\n",
        "**Qué mide:** Diversidad temática de las recomendaciones, es decir, cuántos *clusters* distintos aparecen dentro de una lista recomendada.\n",
        "\n",
        "$$\n",
        "\\text{ClusterDiversity} = \\frac{1}{M} \\sum_{i=1}^{M} \\frac{|C_i^{unique}|}{|C_i|}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "- $M$ = número total de listas (ej. número de videos en test)\n",
        "- $C_i$ = conjunto de clusters de los videos recomendados para el video $i$\n",
        "\n",
        "**Interpretación:**\n",
        "- Evalúa la **diversidad de temas** presentes en las recomendaciones.\n",
        "- Valor alto = lista con varios temas; valor bajo = lista concentrada en un solo tema.\n",
        "\n",
        "---\n",
        "\n",
        "##### **BubbleIndex**\n",
        "**Qué mide:** Grado de concentración de las recomendaciones en el mismo *cluster temático* que el video de origen. Refleja el nivel de \"burbuja algorítmica\".\n",
        "\n",
        "$$\n",
        "\\text{BubbleIndex}(v) = \\frac{1}{K} \\sum_{i=1}^{K} \\mathbb{1}_{[c_i = c_0]}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "- $c_0$ = cluster del video de referencia (video base)\n",
        "- $c_i$ = cluster del video recomendado $i$\n",
        "- $\\mathbb{1}_{[\\text{condición}]}$ = 1 si la condición se cumple, 0 en caso contrario\n",
        "\n",
        "**Interpretación:**\n",
        "- Valores cercanos a 1 → recomendaciones muy concentradas (burbuja fuerte).\n",
        "- Valores cercanos a 0 → recomendaciones más diversas entre temas.\n",
        "\n",
        "---\n",
        "\n",
        "##### **Resumen comparativo de métricas**\n",
        "\n",
        "| Métrica | Tipo | Qué mide | Ideal |\n",
        "|----------|------|-----------|--------|\n",
        "| Precision@K | Relevancia | Exactitud local de recomendaciones | Alto |\n",
        "| Recall@K | Relevancia | Capacidad de recuperar lo visto | Alto |\n",
        "| Coverage | Variedad global | Porcentaje del catálogo cubierto | Alto |\n",
        "| Diversity | Variedad local | Diferencia semántica dentro de lista | Alto |\n",
        "| ClusterDiversity | Variedad temática | Diferencia entre clusters recomendados | Alto |\n",
        "| BubbleIndex | Sesgo temático | Grado de burbuja algorítmica | Bajo |\n",
        "\n",
        "---\n",
        "\n",
        "##### **Configuración temporal utilizada**\n",
        "Las métricas de precisión y recall se calculan considerando una ventana temporal de **24 horas** después de la visualización original:\n",
        "\n",
        "$$\n",
        "\\text{window_hours} = 24\n",
        "$$\n",
        "\n",
        "Esto significa que un video recomendado se considera relevante si el usuario lo vio dentro de las siguientes 24 horas después del video de referencia."
      ],
      "metadata": {
        "id": "cUVFgy5mzO8L"
      },
      "id": "cUVFgy5mzO8L"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Ground truth temporal\n",
        "# ============================================================\n",
        "def get_true_set_by_time(vid, test, train, window_hours=24):\n",
        "    \"\"\"\n",
        "    Obtiene los videos realmente vistos después de un video base, dentro de una ventana temporal.\n",
        "    Sirve como “ground truth” temporal para evaluar si las recomendaciones anticipan el comportamiento del usuario.\n",
        "    \"\"\"\n",
        "    row = test.loc[test[\"video_id\"] == vid].iloc[0]\n",
        "    t0 = row[\"timestamp\"]\n",
        "    mask = (\n",
        "        (test[\"timestamp\"] > t0) &\n",
        "        (test[\"timestamp\"] <= t0 + pd.Timedelta(hours=window_hours))\n",
        "    )\n",
        "    true_set = set(test.loc[mask, \"video_id\"]) - {vid}\n",
        "    return true_set\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Métricas de evaluación\n",
        "# ============================================================\n",
        "def precision_at_k(recommended, true_set):\n",
        "    if len(recommended) == 0: return 0.0\n",
        "    hit = sum(1 for x in recommended if x in true_set)\n",
        "    return hit / len(recommended)\n",
        "\n",
        "def recall_at_k(recommended, true_set):\n",
        "    if len(true_set) == 0: return 0.0\n",
        "    hit = sum(1 for x in recommended if x in true_set)\n",
        "    return hit / len(true_set)\n",
        "\n",
        "def coverage(rec_lists, all_items):\n",
        "    recs = set(x for sub in rec_lists for x in sub)\n",
        "    return len(recs) / len(all_items)\n",
        "\n",
        "def diversity(rec_lists, df, emb_col=\"content_vec\"):\n",
        "    vals = []\n",
        "    for rec in rec_lists:\n",
        "        if len(rec) < 2: continue\n",
        "        vecs = np.vstack([\n",
        "            df.loc[df[\"video_id\"] == v, emb_col].values[0]\n",
        "            for v in rec if v in df[\"video_id\"].values\n",
        "        ])\n",
        "        sim = cosine_similarity(vecs)\n",
        "        vals.append(1 - np.mean(sim[np.triu_indices_from(sim, 1)]))\n",
        "    return np.mean(vals) if vals else 0.0\n",
        "\n",
        "# ============================================================\n",
        "# Métricas temáticas\n",
        "# ============================================================\n",
        "def diversity_clusters(rec_lists, df, cluster_col=\"cluster\"):\n",
        "    vals = []\n",
        "    for rec in rec_lists:\n",
        "        clusters = df.loc[df[\"video_id\"].isin(rec), cluster_col].dropna().values\n",
        "        if len(clusters) > 1:\n",
        "            vals.append(len(np.unique(clusters)) / len(clusters))\n",
        "    return np.mean(vals) if vals else 0.0\n",
        "\n",
        "def bubble_index(video_id, recs, df, cluster_col=\"cluster\"):\n",
        "    if cluster_col not in df.columns: return np.nan\n",
        "    if video_id not in df[\"video_id\"].values: return np.nan\n",
        "    c0 = df.loc[df[\"video_id\"] == video_id, cluster_col].values[0]\n",
        "    rec_clusters = df.loc[df[\"video_id\"].isin(recs), cluster_col].dropna().values\n",
        "    if len(rec_clusters) == 0:\n",
        "        return np.nan\n",
        "    return np.mean(rec_clusters == c0)"
      ],
      "metadata": {
        "id": "rmH7x1x1txWp"
      },
      "id": "rmH7x1x1txWp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Modelado\n",
        "\n",
        "A continuación se explica, cómo funcionan las tres funciones de recomendación mostradas en el código: **popularidad**, **basado en contenido** y **híbrido**.\n",
        "\n",
        "- **Popularidad**: baseline, cero personalización. Útil para cobertura y arranque.\n",
        "- **Contenido**: personaliza por *tema/semántica*, ignora tiempo/canales.\n",
        "- **Híbrido**: combinación ponderada de semántica + contexto + afinidad (suscripción/categorías), suele rendir mejor en *precision@K* cuando el contexto importa.\n"
      ],
      "metadata": {
        "id": "3igAJCcePItd"
      },
      "id": "3igAJCcePItd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 8.1 Contexto mínimo (variables y datos)\n"
      ],
      "metadata": {
        "id": "d0M10f6TnRD4"
      },
      "id": "d0M10f6TnRD4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `train`: subconjunto de entrenamiento con columnas como `video_id`, `content_vec` (embeddings del contenido), `hour`, `weekday`, `channel_title`, `category`, `subtopic`, `format`, `is_subscribed`.\n",
        "- `test`: subconjunto de prueba que contiene, al menos, `video_id` y `content_vec` (para encontrar vecinos similares).\n",
        "- `K` (por defecto `10`): número de recomendaciones a devolver.\n",
        "- Utilidades:\n",
        "  - `normalize`: normalización L2 (longitud unitaria) de vectores.\n",
        "  - `cosine_similarity`: similitud coseno entre vectores/matrices.\n",
        "\n",
        "> Nota: El código asume que `content_vec` es un vector NumPy (p.ej., de 300 dimensiones). Si no lo es, lo convierte/normaliza; y si algún vector en `train` no es `ndarray`, lo reemplaza por un vector **cero** del mismo tamaño para mantener la dimensionalidad.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "39W9h1qeoG-G"
      },
      "id": "39W9h1qeoG-G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2  Recomendador por **Popularidad**"
      ],
      "metadata": {
        "id": "ZtDIT8M5nVxZ"
      },
      "id": "ZtDIT8M5nVxZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Función**: `recommend_popularity(video_id=None, k=K)`\n",
        "\n",
        "#### Qué hace\n",
        "Ignora el `video_id` de entrada y **siempre** devuelve los `k` videos más vistos en el conjunto `train`.\n",
        "\n",
        "#### Cómo funciona\n",
        "1. **Precómputo**: `top_items = train[\"video_id\"].value_counts().head(100).index.tolist()`\n",
        "   - Cuenta ocurrencias de cada `video_id` en `train`\n",
        "   - Se queda con el top-100 y lo guarda en una lista.\n",
        "2. **Recomendación**: devuelve `top_items[:k]`.\n",
        "\n",
        "#### Ventajas\n",
        "- **Simplicidad** y robustez ante frío de ítem/usuario (no depende del `video_id` de consulta).\n",
        "- Sirve como **baseline** razonable.\n",
        "\n",
        "#### Limitaciones\n",
        "- No personaliza: sugiere lo mismo a todos.\n",
        "- Puede reforzar sesgos hacia creadores o temas dominantes"
      ],
      "metadata": {
        "id": "bbhflTJhoNeG"
      },
      "id": "bbhflTJhoNeG"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Popularidad ---\n",
        "def recommend_popularity(video_id=None, k=10):\n",
        "    \"\"\"Siempre recomienda los más populares del train.\"\"\"\n",
        "    top_items = train[\"video_id\"].value_counts().head(100).index.tolist()\n",
        "    k = int(k)\n",
        "    return top_items[:k]"
      ],
      "metadata": {
        "id": "BmjTI3rsnZC1"
      },
      "id": "BmjTI3rsnZC1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.3 Recomendador **Basado en Contenido**\n"
      ],
      "metadata": {
        "id": "Q8Ehi7OgnrDZ"
      },
      "id": "Q8Ehi7OgnrDZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Función**: `recommend_content_based(video_id, train=train, test=test, k=K)`\n",
        "\n",
        "#### Qué hace\n",
        "Dado un `video_id` de `test`, encuentra en `train` los videos **más similares** en términos del vector de contenido (`content_vec`) y devuelve los `k` más parecidos, **excluyendo** recomendar el mismo `video_id`.\n",
        "\n",
        "#### Pasos internos\n",
        "1. **Chequeo de existencia**: si `video_id` no está en `test[\"video_id\"]`, retorna `[]` (no válido).\n",
        "2. **Vector objetivo**: extrae `target_vec = test.loc[test[\"video_id\"]==video_id, \"content_vec\"].values[0]`.\n",
        "   - Lo asegura como `np.ndarray` y lo **normaliza L2**: `target_vec = normalize(target_vec.reshape(1, -1))`.\n",
        "3. **Matriz de contenido del train**:\n",
        "   - Construye `mat = np.vstack([...])` con los `content_vec` de `train`.\n",
        "   - Si algún vector no es `ndarray`, lo sustituye por `np.zeros(300)` (mantener dimensión).\n",
        "   - **Normaliza L2** toda la matriz: `mat = normalize(mat)`.\n",
        "4. **Similitudes coseno**: `sims = cosine_similarity(target_vec, mat).ravel()`.\n",
        "5. **Evitar auto-recomendación**: si `train[\"video_id\"] == video_id`, fuerza su similitud a `-1.0`.\n",
        "6. **Top-K**: ordena de mayor a menor y toma índices `top_idx = np.argsort(sims)[::-1][:k]`.\n",
        "7. **Salida**: `train.iloc[top_idx][\"video_id\"].tolist()`.\n",
        "\n",
        "#### Intuición\n",
        "- La **similitud coseno** prioriza la dirección del embedding, capturando parecido semántico (título, descripción, transcript, etc.).\n",
        "- La **normalización L2** evita que la magnitud del vector domine la similitud.\n",
        "\n",
        "#### Ventajas\n",
        "- Recomendaciones **relevantes por tema/semántica**.\n",
        "- No requiere datos de interacción del usuario (solo del contenido).\n",
        "\n",
        "#### Limitaciones y cuidados\n",
        "- Si hay `content_vec` faltantes o ruidosos, la calidad baja (los ceros actúan como “neutros”).\n",
        "- No incorpora señales temporales/horarias ni afinidad personal (suscripción, histórico individual)."
      ],
      "metadata": {
        "id": "VCuXTYPjomWy"
      },
      "id": "VCuXTYPjomWy"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Contenido ---\n",
        "def recommend_content_based(video_id, train=train, test=test, k=10):\n",
        "    if video_id not in test[\"video_id\"].values:\n",
        "        return []\n",
        "    target_vec = test.loc[test[\"video_id\"] == video_id, \"content_vec\"].values[0]\n",
        "    if not isinstance(target_vec, np.ndarray):\n",
        "        target_vec = np.array(target_vec, dtype=float)\n",
        "    target_vec = normalize(target_vec.reshape(1, -1))\n",
        "    mat = np.vstack([\n",
        "        x if isinstance(x, np.ndarray) else np.zeros(300)\n",
        "        for x in train[\"content_vec\"].values\n",
        "    ])\n",
        "    mat = normalize(mat)\n",
        "    sims = cosine_similarity(target_vec, mat).ravel()\n",
        "    mask_same = (train[\"video_id\"].values == video_id)\n",
        "    sims = np.where(mask_same, -1.0, sims)\n",
        "    top_idx = np.argsort(sims)[::-1][:k]\n",
        "    return train.iloc[top_idx][\"video_id\"].tolist()"
      ],
      "metadata": {
        "id": "TvodspAHnwOa"
      },
      "id": "TvodspAHnwOa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 8.4 Recomendador **Híbrido** (Contenido + Contexto/Categorías)\n"
      ],
      "metadata": {
        "id": "t-BEZRxNnz9R"
      },
      "id": "t-BEZRxNnz9R"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Función**: `recommend_hybrid(video_id, train=train, test=test, k=K, w=None)`\n",
        "\n",
        "#### Qué hace\n",
        "Combina la **similitud textual** (embeddings) con señales **contextuales y categóricas**: hora del día, día de semana, mismo canal, categoría, subtema, formato, y un **ajuste por suscripción**. Devuelve los `k` videos de `train` con mayor puntuación híbrida, excluyendo el mismo `video_id`.\n",
        "\n",
        "#### Pasos internos\n",
        "1. **Chequeo de existencia**: si el `video_id` no está en `test`, retorna `[]`.\n",
        "2. **Fila objetivo**: `row = test.loc[test[\"video_id\"]==video_id].iloc[0]`.\n",
        "3. **Normalización de tiempo**:\n",
        "   - `weekday` mapeado a entero `[0..6]` usando `mapping = {\"Monday\":0, …, \"Sunday\":6}` si viniera como string/categoría.\n",
        "4. **Similitudes de cada componente**:\n",
        "   - **Texto (embeddings)**: `q = row[\"content_vec\"].reshape(1,-1)`; `mat = normalize(vstack(train[\"content_vec\"]))`; `s_text = cosine_similarity(q, mat).ravel()`.\n",
        "   - **Hora** (circularidad 24h) y **día** (circularidad 7d): se usa una **similitud circular**:\n",
        "     \n",
        "     $$\\Delta = |a-b|; \\quad \\Delta = \\min(\\Delta, \\text{period} - \\Delta)$$\n",
        "     $$s_\\text{circ}(a,b) = \\frac{1 + \\cos\\left(\\pi \\frac{\\Delta}{\\text{period}/2}\\right)}{2}$$\n",
        "     \n",
        "     - Esto da 1 cuando la diferencia horaria/semana es 0, decae a 0 en media vuelta (12h o 3.5 días) y vuelve a 1 en una vuelta completa.\n",
        "     - Implementado como `s_hour` y `s_week`.\n",
        "   - **Categorías exactas** (indicadores binarios):\n",
        "     - `s_channel = 1` si mismo `channel_title`, si no `0`.\n",
        "     - `s_cat`, `s_sub`, `s_fmt` análogos para `category`, `subtopic`, `format`.\n",
        "5. **Ponderación (pesos `w`)**:\n",
        "   - Por defecto: `w = {text:0.55, hour:0.10, weekday:0.05, channel:0.10, category:0.08, subtopic:0.07, fmt:0.03, subscribed_boost:0.02, interact_boost:0.00}`.\n",
        "   - Puntuación base (antes de boosts):\n",
        "     \n",
        "     $$\n",
        "     s = w_{text}\\, s_{text} + w_{hour}\\, s_{hour} + w_{weekday}\\, s_{week} + w_{channel}\\, s_{channel} + w_{category}\\, s_{cat} + w_{subtopic}\\, s_{sub} + w_{fmt}\\, s_{fmt}\n",
        "     $$\n",
        "\n",
        "6. **Ajuste por suscripción**:\n",
        "   - Si `train[\"is_subscribed\"]` es 1, multiplica: `s *= (1 + w[\"subscribed_boost\"] * subscribed)`.\n",
        "   - Aumenta ligeramente videos de **canales a los que estás suscrito**.\n",
        "   - *Nota*: `interact_boost` aparece en los pesos, pero en la versión mostrada **no se usa** (posible campo futuro para likes, comentarios, etc.).\n",
        "7. **Evitar auto-recomendación**: fuerza `-1.0` si `train[\"video_id\"] == video_id`.\n",
        "8. **Top-K**: ordena `s` y devuelve los `k` mayores `video_id`.\n",
        "\n",
        "#### Intuición\n",
        "- Mezcla **semejanza semántica** (contenido) con **contexto de consumo** (hora/día) y **afinidad explícita** (mismo canal/suscripción), mejorando la relevancia temporal y de preferencia.\n",
        "\n",
        "#### Ventajas\n",
        "- Más **personalizable** y sensible al **contexto** que el puro contenido.\n",
        "- Control fino vía **pesos** `w` según métricas offline/online.\n",
        "\n",
        "#### Limitaciones y cuidados\n",
        "- Requiere datos limpios en columnas de contexto; si vienen como texto/categoría sin mapear, hay que convertirlos a numéricos (el código ya contempla mapeo de `weekday`).\n",
        "- Una mala elección de **pesos** puede sesgar en exceso hacia ciertos canales/categorías.\n",
        "- El boost de suscripción es **multiplicativo**; conviene validar su impacto con métricas.\n"
      ],
      "metadata": {
        "id": "wxOzt1lTvCZl"
      },
      "id": "wxOzt1lTvCZl"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Híbrido ---\n",
        "def recommend_hybrid(video_id, train=train, test=test, k=10, w=None):\n",
        "    if video_id not in test[\"video_id\"].values:\n",
        "        return []\n",
        "\n",
        "    row = test.loc[test[\"video_id\"] == video_id].iloc[0]\n",
        "\n",
        "    # Asegurar que weekday/hora sean numéricos (evita errores tipo 'Friday')\n",
        "    mapping = {\n",
        "        \"Monday\": 0, \"Tuesday\": 1, \"Wednesday\": 2, \"Thursday\": 3,\n",
        "        \"Friday\": 4, \"Saturday\": 5, \"Sunday\": 6\n",
        "    }\n",
        "\n",
        "    if isinstance(row[\"weekday\"], str):\n",
        "        row[\"weekday\"] = mapping.get(row[\"weekday\"], np.nan)\n",
        "\n",
        "    if train[\"weekday\"].dtype == object or str(train[\"weekday\"].dtype).startswith(\"category\"):\n",
        "        train[\"weekday\"] = train[\"weekday\"].map(mapping)\n",
        "\n",
        "    # Define similitud circular\n",
        "    def circular_sim(a, b, period):\n",
        "        a, b = float(a), b.astype(float)\n",
        "        delta = np.abs(a - b)\n",
        "        delta = np.minimum(delta, period - delta)\n",
        "        return (1 + np.cos(np.pi * delta / (period / 2))) / 2\n",
        "\n",
        "    # Pesos por defecto\n",
        "    if w is None:\n",
        "        w = dict(text=0.55, hour=0.10, weekday=0.05,\n",
        "                 channel=0.10, category=0.08, subtopic=0.07,\n",
        "                 fmt=0.03, subscribed_boost=0.02, interact_boost=0.00)\n",
        "\n",
        "    # Similitudes\n",
        "    q = row[\"content_vec\"].reshape(1, -1)\n",
        "    mat = np.vstack(train[\"content_vec\"].values)\n",
        "    mat = normalize(mat)\n",
        "\n",
        "    s_text = cosine_similarity(q, mat).ravel()\n",
        "    s_hour = circular_sim(row[\"hour\"], train[\"hour\"].values, 24)\n",
        "    s_week = circular_sim(row[\"weekday\"], train[\"weekday\"].values, 7)\n",
        "    s_channel = (train[\"channel_title\"].values == row[\"channel_title\"]).astype(float)\n",
        "    s_cat     = (train[\"category\"].values == row[\"category\"]).astype(float)\n",
        "    s_sub     = (train[\"subtopic\"].values == row[\"subtopic\"]).astype(float)\n",
        "    s_fmt     = (train[\"format\"].values == row[\"format\"]).astype(float)\n",
        "\n",
        "    # Ajustes por suscripción\n",
        "    subscribed = train[\"is_subscribed\"].fillna(0).values.astype(float)\n",
        "\n",
        "    s = (w[\"text\"]*s_text + w[\"hour\"]*s_hour + w[\"weekday\"]*s_week +\n",
        "         w[\"channel\"]*s_channel + w[\"category\"]*s_cat +\n",
        "         w[\"subtopic\"]*s_sub + w[\"fmt\"]*s_fmt)\n",
        "    s *= (1 + w[\"subscribed_boost\"] * subscribed)\n",
        "\n",
        "    # Evitar recomendar el mismo video\n",
        "    mask_same = (train[\"video_id\"].values == video_id)\n",
        "    sims = np.where(mask_same, -1.0, s)\n",
        "    top_idx = np.argsort(sims)[::-1][:k]\n",
        "\n",
        "    return train.iloc[top_idx][\"video_id\"].tolist()"
      ],
      "metadata": {
        "id": "fNjXmAvFn4Rq"
      },
      "id": "fNjXmAvFn4Rq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.6 T-SNE Y Kmeans\n",
        "Dado que las métricas de evaluación que diseñé utilizan cluster temáticos, es necesario realizar y aplicar estos algoritmos de reducción como el TSNE y Kmeans sobre el conjunto de datos complet (Recordemos que en el EDA fue solo sobre unamuestra).\n",
        "\n",
        "\n",
        "Esto permite entender qué tan variado o encerrado es el conjunto de recomendaciones.\n",
        "\n",
        "Por eso el proyecto incluye métricas como:\n",
        "\n",
        "* Diversity\n",
        "* ClusterDiversity\n",
        "* BubbleIndex"
      ],
      "metadata": {
        "id": "t2g3l9noqVF9"
      },
      "id": "t2g3l9noqVF9"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# K-Means clustering temático con barra de progreso\n",
        "# ============================================================\n",
        "from tqdm.auto import tqdm\n",
        "from time import sleep\n",
        "\n",
        "print(\"\\nEntrenando K-Means temático sobre embeddings t-SNE...\")\n",
        "\n",
        "sample_vecs = np.vstack(df_embed[\"content_vec\"].values)\n",
        "\n",
        "# --- t-SNE con barra de progreso simulada ---\n",
        "# (t-SNE no expone callbacks, así que mostramos una barra de \"espera\")\n",
        "n_steps = 20  # número de pasos visibles (ajustable)\n",
        "with tqdm(total=n_steps, desc=\"Calculando t-SNE\", bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt}\") as pbar:\n",
        "    tsne = TSNE(\n",
        "        n_components=2,\n",
        "        perplexity=40,\n",
        "        random_state=42,\n",
        "        init=\"random\",\n",
        "        learning_rate=\"auto\"\n",
        "    )\n",
        "    # Ejecutar t-SNE mientras mostramos la barra\n",
        "    for i in range(n_steps):\n",
        "        sleep(0.05)  # simula progreso mientras se ajusta\n",
        "        pbar.update(1)\n",
        "    tsne_coords = tsne.fit_transform(normalize(sample_vecs))\n",
        "\n",
        "df_embed[\"tsne_1\"] = tsne_coords[:, 0]\n",
        "df_embed[\"tsne_2\"] = tsne_coords[:, 1]\n",
        "\n",
        "# --- K-Means con progreso real ---\n",
        "print(\"\\nAplicando K-Means...\")\n",
        "kmeans = KMeans(n_clusters=8, random_state=42, n_init=10, verbose=0)\n",
        "\n",
        "# tqdm para mostrar progreso del fit_predict\n",
        "with tqdm(total=len(df_embed), desc=\"Clustering K-Means\", bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt}\") as pbar:\n",
        "    df_embed[\"cluster\"] = kmeans.fit_predict(df_embed[[\"tsne_1\", \"tsne_2\"]])\n",
        "    pbar.update(len(df_embed))\n",
        "\n",
        "# Propagar a train/test\n",
        "train[\"cluster\"] = df_embed.loc[train.index, \"cluster\"].values\n",
        "test[\"cluster\"]  = df_embed.loc[test.index, \"cluster\"].values\n",
        "\n",
        "print(\"Clustering completado.\")"
      ],
      "metadata": {
        "id": "iTw3znp8qosJ"
      },
      "id": "iTw3znp8qosJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.7 Evaluar y comparar modelos"
      ],
      "metadata": {
        "id": "Qlw5un1Jrlc_"
      },
      "id": "Qlw5un1Jrlc_"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Evaluación comparativa\n",
        "# ============================================================\n",
        "K=10\n",
        "all_items = set(train[\"video_id\"].unique())\n",
        "results = []\n",
        "algos = {\n",
        "    \"Popularidad\": recommend_popularity,\n",
        "    \"Contenido\": recommend_content_based,\n",
        "    \"Híbrido\": recommend_hybrid\n",
        "}\n",
        "\n",
        "for name, func in algos.items():\n",
        "    print(f\"\\nEvaluando {name}...\")\n",
        "    precs, recs, lists, bubbles = [], [], [], []\n",
        "\n",
        "    for vid in tqdm(test[\"video_id\"].values[:500]):  # muestra por velocidad\n",
        "        true_set = get_true_set_by_time(vid, test, train, window_hours=24)\n",
        "        if len(true_set) == 0:\n",
        "            continue\n",
        "        rec = func(vid, k=K)\n",
        "        lists.append(rec)\n",
        "        precs.append(precision_at_k(rec, true_set))\n",
        "        recs.append(recall_at_k(rec, true_set))\n",
        "        bubbles.append(bubble_index(vid, rec, train))\n",
        "\n",
        "    results.append({\n",
        "        \"Algoritmo\": name,\n",
        "        \"Precision@10\": np.mean(precs),\n",
        "        \"Recall@10\": np.mean(recs),\n",
        "        \"Coverage\": coverage(lists, all_items),\n",
        "        \"Diversity\": diversity(lists, train),\n",
        "        \"ClusterDiversity\": diversity_clusters(lists, train),\n",
        "        \"BubbleIndex\": np.nanmean(bubbles)\n",
        "    })\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\n Comparativa final:\\n\", df_results)"
      ],
      "metadata": {
        "id": "6q8RKtwjqEbj"
      },
      "id": "6q8RKtwjqEbj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Visualizaciones\n",
        "# ============================================================\n",
        "\n",
        "# --- Comparativa de modelos ---\n",
        "fig = px.bar(\n",
        "    df_results.melt(id_vars=\"Algoritmo\", var_name=\"Métrica\", value_name=\"Valor\"),\n",
        "    x=\"Métrica\", y=\"Valor\", color=\"Algoritmo\",\n",
        "    barmode=\"group\", text_auto=\".3f\",\n",
        "    title=\"Comparativa de Recomendadores (Temporal + Temático)\"\n",
        ")\n",
        "fig.update_layout(template=\"plotly_white\", yaxis_title=\"Valor promedio\")\n",
        "fig.show()\n",
        "\n",
        "# --- Visualización de clusters t-SNE ---\n",
        "fig = px.scatter(\n",
        "    df_embed,\n",
        "    x=\"tsne_1\",\n",
        "    y=\"tsne_2\",\n",
        "    color=\"cluster\",\n",
        "    hover_name=\"video_title\",\n",
        "    hover_data={\"category\": True, \"channel_title\": True},\n",
        "    title=f\"t-SNE + K-Means clusters — Agrupamiento de videos por contenido\",\n",
        "    color_continuous_scale=\"Turbo\",\n",
        ")\n",
        "fig.update_traces(\n",
        "    marker=dict(size=6, opacity=0.8, line=dict(width=0.4, color=\"white\"))\n",
        ")\n",
        "fig.update_layout(width=950, height=750, template=\"plotly_white\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "vpGwL4LnnBF4"
      },
      "id": "vpGwL4LnnBF4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##### **Popularidad**\n",
        "- **Recomendador baseline.** No usa información del usuario ni del video de entrada.\n",
        "- **Precisión/Recall:** bajos (0.014 y 0.004). No personaliza, por lo que acierta poco.\n",
        "- **Cobertura:** casi nula (0.0007). Siempre recomienda los mismos videos populares.\n",
        "- **Diversidad aparente:** 0.27 (moderada), pero engañosa: recomienda el mismo grupo reducido.\n",
        "- **ClusterDiversity:** 0.008 → muestra repetición de los mismos temas/canales.\n",
        "- **BubbleIndex:** 0.106 → bajo porque no personaliza, no hay “burbuja”.\n",
        "\n",
        "**Conclusión:** útil solo como referencia o arranque en frío. No ofrece personalización real.\n",
        "\n",
        "---\n",
        "\n",
        "##### **Basado en Contenido**\n",
        "- **Personalización semántica:** usa embeddings de texto (título, descripción, etc.).\n",
        "- **Precision/Recall:** ligeramente inferiores en precisión pero mejores en recall (0.0041).\n",
        "- **Cobertura:** 0.131 → muy superior; recomienda videos variados del catálogo.\n",
        "- **Diversidad:** 0.165 → más homogéneo (agrupa por temas similares).\n",
        "- **ClusterDiversity:** 0.094 → buena variedad temática.\n",
        "- **BubbleIndex:** 0.859 → alto; indica fuerte efecto burbuja (repite el mismo tipo de contenido).\n",
        "\n",
        "**Conclusión:** ofrece relevancia semántica pero tiende al “efecto túnel” (recomienda solo lo similar al historial del usuario).\n",
        "\n",
        "---\n",
        "\n",
        "##### **Híbrido (Contenido + Contexto)**\n",
        "- Combina similitud semántica con contexto (hora, día, canal, categoría, suscripción).\n",
        "- **Precision/Recall:** ligeramente superiores (0.010 / 0.008). Mejor cobertura del gusto real.\n",
        "- **Cobertura:** 0.128 → comparable a contenido, alto.\n",
        "- **Diversidad:** 0.194 → mejora respecto al contenido puro.\n",
        "- **ClusterDiversity:** 0.095 → amplia variedad temática.\n",
        "- **BubbleIndex:** 0.809 → algo menor que el modelo de contenido, muestra menor encierro.\n",
        "\n",
        "**Conclusión:** el mejor compromiso global entre relevancia, cobertura y diversidad. Reduce parcialmente la burbuja.\n",
        "\n",
        "---\n",
        "\n",
        "##### **Comparación global**\n",
        "| Modelo | Relevancia | Cobertura | Diversidad | Burbuja |\n",
        "|---------|-------------|------------|-------------|----------|\n",
        "| Popularidad | ❌ Baja | ❌ Muy baja | ⚠️ Moderada aparente | ✅ Sin burbuja |\n",
        "| Contenido | ⚠️ Media | ✅ Alta | ⚠️ Baja | ❌ Alta burbuja |\n",
        "| Híbrido | ✅ Equilibrada | ✅ Alta | ✅ Buena | ⚠️ Menor burbuja |\n",
        "\n",
        "- **Popularidad**: baseline con alto sesgo hacia videos populares.\n",
        "- **Contenido**: personaliza por tema, pero refuerza burbujas algorítmicas.\n",
        "- **Híbrido**: equilibra relevancia y diversidad, con un BubbleIndex más bajo.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FWbnxRCsiTaO"
      },
      "id": "FWbnxRCsiTaO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.8  Generar recomendaciones"
      ],
      "metadata": {
        "id": "Bg1d0Bsy0tX7"
      },
      "id": "Bg1d0Bsy0tX7"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Ejemplo aleatorio: comparar recomendaciones de los 3 modelos\n",
        "# ============================================================\n",
        "\n",
        "# Elegimos un video aleatorio del set de test\n",
        "import random\n",
        "video_ejemplo = random.choice(test[\"video_id\"].tolist())\n",
        "print(f\"Video base: {video_ejemplo}\")\n",
        "\n",
        "# Obtenemos metadatos del video (si existen)\n",
        "base_info = test.loc[test[\"video_id\"] == video_ejemplo,\n",
        "                     [\"video_title\", \"channel_title\", \"category\", \"subtopic\"]].iloc[0]\n",
        "print(f\"Título: {reverse_lookup('video_title', base_info['video_title'])}\",hash_maps)\n",
        "print(f\"Canal: {reverse_lookup('channel_title', base_info['channel_title'])}\",hash_maps)\n",
        "print(f\"Categoría: {reverse_lookup('category', base_info['category'],hash_maps)} | Subtema: {reverse_lookup('subtopic', base_info['subtopic'],hash_maps)}\")\n",
        "\n",
        "# ============================================================\n",
        "# Generar recomendaciones Top-5 con cada modelo\n",
        "# ============================================================\n",
        "\n",
        "top_k = 5  # cantidad de recomendaciones a mostrar\n",
        "\n",
        "recs_pop = recommend_popularity(video_ejemplo, k=top_k)\n",
        "recs_cont = recommend_content_based(video_ejemplo, train=train, test=test, k=top_k)\n",
        "recs_hibr = recommend_hybrid(video_ejemplo, train=train, test=test, k=top_k)\n",
        "\n",
        "# ============================================================\n",
        "# Mostrar resultados comparativos\n",
        "# ============================================================\n",
        "\n",
        "def mostrar_recs(label, recs):\n",
        "    print(f\"\\n{label} — {len(recs)} recomendaciones:\")\n",
        "    for i, vid in enumerate(recs, 1):\n",
        "        if vid in train[\"video_id\"].values:\n",
        "            info = train.loc[train[\"video_id\"] == vid,\n",
        "                             [\"video_title\", \"channel_title\", \"category\", \"subtopic\"]].iloc[0]\n",
        "\n",
        "            # Revertir los hashes para mostrar valores originales\n",
        "            title_real = reverse_lookup(\"video_title\", info[\"video_title\"],hash_maps)\n",
        "            channel_real = reverse_lookup(\"channel_title\", info[\"channel_title\"],hash_maps)\n",
        "            cat_real = reverse_lookup(\"category\", info[\"category\"],hash_maps)\n",
        "            sub_real = reverse_lookup(\"subtopic\", info[\"subtopic\"],hash_maps)\n",
        "\n",
        "            print(f\"  {i}. {title_real}  |  Canal: {channel_real}  |  Cat: {cat_real}  |  Sub: {sub_real}\")\n",
        "        else:\n",
        "            print(f\"  {i}. {vid}\")\n",
        "\n",
        "mostrar_recs(\"Popularidad\", recs_pop)\n",
        "mostrar_recs(\"Contenido\", recs_cont)\n",
        "mostrar_recs(\"Híbrido\", recs_hibr)"
      ],
      "metadata": {
        "id": "yWdecZsT0srm"
      },
      "id": "yWdecZsT0srm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Analisis de burbuja"
      ],
      "metadata": {
        "id": "gG5YXgNw5Ath"
      },
      "id": "gG5YXgNw5Ath"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.1 Evolución temporal del consumo por cluster temático"
      ],
      "metadata": {
        "id": "PkfonR2tyIqH"
      },
      "id": "PkfonR2tyIqH"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Evolución temporal del consumo por cluster temático\n",
        "# ============================================================\n",
        "\n",
        "# Asegurar que timestamp sea datetime\n",
        "df_embed[\"timestamp\"] = pd.to_datetime(df_embed[\"timestamp\"], errors=\"coerce\")\n",
        "\n",
        "# Crear columna de mes (año-mes)\n",
        "df_time = (\n",
        "    df_embed\n",
        "    .assign(month=df_embed[\"timestamp\"].dt.to_period(\"M\").astype(str))\n",
        "    .groupby([\"month\", \"cluster\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"count\")\n",
        "    .sort_values(\"month\")\n",
        ")\n",
        "\n",
        "print(f\"Datos temporales listos: {df_time['month'].nunique()} meses, {df_time['cluster'].nunique()} clusters\")\n",
        "\n",
        "# Paleta de colores\n",
        "color_scale = pc.sequential.Turbo  # paleta continua vibrante\n",
        "\n",
        "# Visualización temporal\n",
        "fig = px.line(\n",
        "    df_time,\n",
        "    x=\"month\",\n",
        "    y=\"count\",\n",
        "    color=\"cluster\",\n",
        "    title=\"Evolución temporal del consumo por cluster de contenido\",\n",
        "    markers=True,\n",
        "    color_discrete_sequence=color_scale,\n",
        ")\n",
        "\n",
        "# Opcional: suavizar eje x y mejorar legibilidad\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Mes\",\n",
        "    yaxis_title=\"Cantidad de videos vistos\",\n",
        "    hovermode=\"x unified\",\n",
        "    template=\"plotly_white\",\n",
        "    width=950,\n",
        "    height=550,\n",
        "    legend_title_text=\"Cluster temático\",\n",
        ")\n",
        "\n",
        "# Rotar etiquetas de meses para legibilidad\n",
        "fig.update_xaxes(tickangle=45)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "8uWFhihF5LS5"
      },
      "id": "8uWFhihF5LS5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Evolución trimestral de consumo por cluster\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Asegurar tipo datetime\n",
        "df_embed[\"timestamp\"] = pd.to_datetime(df_embed[\"timestamp\"], errors=\"coerce\")\n",
        "df_valid = df_embed.dropna(subset=[\"timestamp\", \"cluster\"]).copy()\n",
        "df_valid[\"period\"] = df_valid[\"timestamp\"].dt.to_period(\"Q\").astype(str)\n",
        "\n",
        "# --- Conteo por trimestre y cluster ---\n",
        "df_time = (\n",
        "    df_valid\n",
        "    .groupby([\"period\", \"cluster\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"count\")\n",
        ")\n",
        "\n",
        "# --- Proporciones normalizadas ---\n",
        "df_pct = (\n",
        "    df_time\n",
        "    .pivot(index=\"period\", columns=\"cluster\", values=\"count\")\n",
        "    .fillna(0)\n",
        "    .apply(lambda x: x / x.sum(), axis=1)\n",
        "    .reset_index()\n",
        "    .melt(id_vars=\"period\", var_name=\"cluster\", value_name=\"pct\")\n",
        ")\n",
        "\n",
        "# Ordenar períodos cronológicamente\n",
        "df_pct[\"period\"] = pd.Categorical(df_pct[\"period\"], ordered=True, categories=sorted(df_pct[\"period\"].unique()))\n",
        "\n",
        "# Suavizado ligero (rolling mean de 2 trimestres)\n",
        "df_pct[\"pct_smooth\"] = (\n",
        "    df_pct.groupby(\"cluster\")[\"pct\"]\n",
        "    .transform(lambda x: x.rolling(window=2, min_periods=1, center=True).mean())\n",
        ")\n",
        "\n",
        "# Paleta más suave (Pastel)\n",
        "palette = px.colors.qualitative.Pastel + px.colors.qualitative.Bold\n",
        "\n",
        "# ============================================================\n",
        "# Visualización final\n",
        "# ============================================================\n",
        "fig = px.area(\n",
        "    df_pct,\n",
        "    x=\"period\",\n",
        "    y=\"pct_smooth\",\n",
        "    color=\"cluster\",\n",
        "    title=\"Evolución trimestral de consumo por cluster de contenido\",\n",
        "    color_discrete_sequence=palette,\n",
        ")\n",
        "\n",
        "fig.update_traces(\n",
        "    mode=\"lines\",\n",
        "    line_shape=\"spline\",  # curva más suave\n",
        "    hovertemplate=\"<b>Cluster %{legendgroup}</b><br>%{x}: %{y:.1%}<extra></extra>\"\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    template=\"plotly_white\",\n",
        "    xaxis_title=\"Trimestre\",\n",
        "    yaxis_title=\"Proporción de consumo (%)\",\n",
        "    hovermode=\"x unified\",\n",
        "    width=950,\n",
        "    height=520,\n",
        "    legend_title_text=\"Cluster temático\",\n",
        "    font=dict(size=13),\n",
        "    title=dict(x=0.05, xanchor=\"left\", font=dict(size=18)),\n",
        "    margin=dict(l=40, r=20, t=60, b=60),\n",
        "    plot_bgcolor=\"rgba(245,245,250,1)\",\n",
        ")\n",
        "\n",
        "fig.update_yaxes(tickformat=\".0%\", gridcolor=\"rgba(220,220,230,0.4)\")\n",
        "fig.update_xaxes(tickangle=45, showgrid=False)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "XPv12t3Pw7PD"
      },
      "id": "XPv12t3Pw7PD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9.2 Análisis de Concentración y Diversidad Temática"
      ],
      "metadata": {
        "id": "EQSTvmnEyQP5"
      },
      "id": "EQSTvmnEyQP5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este análisis cuantifica **qué tan concentrado** está el consumo en pocos canales o temas, y **qué tan diversa** es la exposición a contenido a través del tiempo. En 3 indicadores:\n",
        "* Entropía de Shannon\n",
        "* Concentración\n",
        "* Distribución de Consumo por Cluster\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### **Entropía de Shannon (Diversidad)**\n",
        "\n",
        "**Qué mide:** La entropía ($H$) mide el grado de incertidumbre o diversidad en una distribución. En este contexto, mide **cuán distribuido** está el consumo entre distintos canales o clusters.\n",
        "\n",
        "$$\n",
        "H = - \\sum_i p_i \\log(p_i)\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "- $p_i$ = proporción de vistas correspondientes al canal o cluster $i$.\n",
        "\n",
        "**Interpretación:**\n",
        "- Entropía alta → consumo distribuido en muchos canales o temas (más diversidad).\n",
        "- Entropía baja → consumo concentrado en pocos canales o temas (mayor homogeneidad o burbuja temática).\n",
        "\n",
        "---\n",
        "\n",
        "#### **Concentración (Top-N Share)**\n",
        "\n",
        "**Qué mide:** Porcentaje del total de vistas concentradas en los principales canales o clusters.\n",
        "\n",
        "Ejemplo:\n",
        "- **Top-10 canales**: porcentaje de vistas acumuladas por los 10 canales más vistos.\n",
        "- **Top-3 clusters**: porcentaje de vistas acumuladas por los 3 temas más consumidos.\n",
        "\n",
        "**Fórmula:**\n",
        "\n",
        "$$\n",
        "\\text{Concentración}_{TopN} = \\sum_{i=1}^{N} p_i\n",
        "$$\n",
        "\n",
        "donde los $p_i$ están ordenados de mayor a menor.\n",
        "\n",
        "**Interpretación:**\n",
        "- Valores altos → unas pocas fuentes dominan el consumo.\n",
        "- Valores bajos → consumo más distribuido entre múltiples temas o canales.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Visualización: Distribución de Consumo por Cluster**\n",
        "\n",
        "Se utiliza un gráfico de barras que muestra la proporción del consumo asignada a cada cluster temático:\n",
        "\n",
        "- El eje X representa los **clusters (temas)**.\n",
        "- El eje Y representa la **proporción de vistas**.\n",
        "\n",
        "Esto permite identificar rápidamente si el consumo se concentra en pocos clusters o si se distribuye de forma más homogénea.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Interpretación conjunta**\n",
        "\n",
        "| Métrica | Qué indica | Ideal |\n",
        "|----------|-------------|--------|\n",
        "| **Entropía alta** | Alta diversidad temática o de fuentes | ✅ Deseable |\n",
        "| **Entropía baja** | Pocos temas dominan el consumo | ⚠️ Posible burbuja |\n",
        "| **Top-N alto** | Alta concentración de consumo | ⚠️ Baja variedad |\n",
        "| **Top-N bajo** | Consumo repartido entre más temas | ✅ Diverso |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "GDmZo0pn6CgV"
      },
      "id": "GDmZo0pn6CgV"
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos el dataset completo con clusters ya calculados\n",
        "df_valid = df_embed.dropna(subset=[\"cluster\", \"channel_title\"]).copy()\n",
        "\n",
        "# ============================================================\n",
        "# Concentración por canal\n",
        "# ============================================================\n",
        "channel_counts = df_valid[\"channel_title\"].value_counts(normalize=True)\n",
        "channel_entropy = entropy(channel_counts)  # entropía de Shannon\n",
        "channel_concentration = channel_counts.head(10).sum()  # top-10 canales\n",
        "\n",
        "print(f\"Entropía de canales: {channel_entropy:.3f}\")\n",
        "print(f\"% de vistas concentradas en top-10 canales: {channel_concentration*100:.1f}%\")\n",
        "\n",
        "# ============================================================\n",
        "# Concentración por tema (cluster)\n",
        "# ============================================================\n",
        "cluster_counts = df_valid[\"cluster\"].value_counts(normalize=True)\n",
        "cluster_entropy = entropy(cluster_counts)\n",
        "cluster_concentration = cluster_counts.head(3).sum()  # top-3 temas\n",
        "\n",
        "print(f\"Entropía de clusters: {cluster_entropy:.3f}\")\n",
        "print(f\"% de vistas concentradas en top-3 temas: {cluster_concentration*100:.1f}%\")\n",
        "\n",
        "# ============================================================\n",
        "# Visualización de distribución temática\n",
        "# ============================================================\n",
        "fig = px.bar(\n",
        "    x=cluster_counts.index.astype(str),\n",
        "    y=cluster_counts.values,\n",
        "    title=\"Distribución del consumo por cluster temático\",\n",
        "    labels={\"x\": \"Cluster\", \"y\": \"Proporción del consumo\"},\n",
        "    color=cluster_counts.index.astype(str),\n",
        "    color_discrete_sequence=px.colors.qualitative.Bold,\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    template=\"plotly_white\",\n",
        "    width=900,\n",
        "    height=500,\n",
        "    showlegend=False,\n",
        "    xaxis_title=\"Cluster temático\",\n",
        "    yaxis_title=\"Proporción del consumo\",\n",
        ")\n",
        "fig.update_yaxes(tickformat=\".0%\")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_UEjW0sTpx6F"
      },
      "id": "_UEjW0sTpx6F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Cluster | Descripción aproximada                                                              | Tipo de contenido dominante    |\n",
        "| ------- | ----------------------------------------------------------------------------------- | ------------------------------ |\n",
        "| **0**   | Entretenimiento variado (gaming, misterio, curiosidades, contenido viral)           | 🎮📺 General / ocio digital    |\n",
        "| **1**   | Música latina urbana (reggaetón, trap, pop latino)                                  | 🎤 Música urbana               |\n",
        "| **2**   | Música alternativa / electrónica / cultural (Macaco, Cultura Profética, Steve Aoki) | 🎧 Fusión indie / electrónica  |\n",
        "| **3**   | Deportes (fútbol, highlights, análisis, noticias deportivas)                        | ⚽ Deportes                     |\n",
        "| **4**   | Música rock y pop-rock (Reik, Evolución, Maná, Jarabe de Palo)                      | 🎸 Rock / Pop clásico          |\n",
        "| **5**   | Educación y aprendizaje (tutoriales, ciencia, tecnología, cursos online)            | 🎓 Educación / Data Science    |\n",
        "| **6**   | Entretenimiento y shows de talento (Got Talent, concursos, reality shows)           | 🎭 Shows / entretenimiento     |\n",
        "| **7**   | Música melódica / pop latino suave (Kadeho, Malpaís, Reik, José Capmany, etc.)      | 🎵 Música romántica / melódica |\n",
        "\n",
        "\n",
        "\n",
        "Interpretación\n",
        "\n",
        "* Alta entropía de canales (7.25) → tu consumo está distribuido entre muchos canales diferentes → alta diversidad de fuentes.\n",
        "\n",
        "* Baja concentración en top-10 (16%) → ningún canal domina claramente tu tiempo de visualización.\n",
        "\n",
        "* Entropía de clusters (2.06) → moderada: indica que consumes de varios temas, pero con una inclinación hacia ciertos géneros.\n",
        "\n",
        "* Top-3 temas = 43.7% del consumo → cerca de la mitad de tus vistas se concentran en 3 temas principales"
      ],
      "metadata": {
        "id": "8ZfJCr_a7x48"
      },
      "id": "8ZfJCr_a7x48"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.3 Análisis de horarios y hábitos"
      ],
      "metadata": {
        "id": "-UaSDGIe0oOF"
      },
      "id": "-UaSDGIe0oOF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Queremos ver si hay sesgos de horario (por ejemplo: ver siempre de noche, o los mismos temas en ciertas horas).\n",
        "Interpretación:\n",
        "\n",
        "Si la mayor parte ocurre a las mismas horas o días → sesgo de horario o hábito (ej. “doomscrolling” nocturno).\n",
        "\n",
        "Puede estar relacionado con tus patrones de recomendación (YouTube aprende cuándo mostrarte cierto tipo de videos)."
      ],
      "metadata": {
        "id": "eh9Se-acqVDd"
      },
      "id": "eh9Se-acqVDd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Visualización              | Qué muestra                                       | Qué puedes detectar                                                    |\n",
        "| -------------------------- | ------------------------------------------------- | ---------------------------------------------------------------------- |\n",
        "| **Histograma por hora**    | Cuándo ves más videos (picos de actividad diaria) | Si hay concentración nocturna o de madrugada → posible *doomscrolling* |\n",
        "| **Histograma por día**     | Qué días consumes más contenido                   | Si el patrón se concentra en fines de semana o días específicos        |\n",
        "| **Mapa de calor hora×día** | Combinación visual de ambos                       | Identifica franjas de tiempo recurrentes de alta actividad             |\n",
        " **Mapa de calor hora×cluster** | Combinación visual de ambos | Concentraciones temáticas en ciertos horarios\n"
      ],
      "metadata": {
        "id": "ElkVoAvd9LbC"
      },
      "id": "ElkVoAvd9LbC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegurar que timestamp sea datetime\n",
        "df_embed[\"timestamp\"] = pd.to_datetime(df_embed[\"timestamp\"], errors=\"coerce\")\n",
        "\n",
        "# Crear variables temporales\n",
        "df_embed[\"hour\"] = df_embed[\"timestamp\"].dt.hour\n",
        "df_embed[\"dayofweek\"] = df_embed[\"timestamp\"].dt.day_name()\n",
        "\n",
        "# ============================================================\n",
        "# Distribución por hora del día\n",
        "# ============================================================\n",
        "fig = px.histogram(\n",
        "    df_embed,\n",
        "    x=\"hour\",\n",
        "    nbins=24,\n",
        "    color=\"cluster\",\n",
        "    title=\"Distribución horaria de visualizaciones por cluster temático\",\n",
        "    barmode=\"overlay\",\n",
        "    color_discrete_sequence=px.colors.qualitative.Bold\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    template=\"plotly_white\",\n",
        "    xaxis_title=\"Hora del día\",\n",
        "    yaxis_title=\"Cantidad de videos vistos\",\n",
        "    hovermode=\"x unified\",\n",
        "    width=950,\n",
        "    height=500,\n",
        "    legend_title_text=\"Cluster temático\"\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "# ============================================================\n",
        "# Distribución por día de la semana\n",
        "# ============================================================\n",
        "fig = px.histogram(\n",
        "    df_embed,\n",
        "    x=\"dayofweek\",\n",
        "    color=\"cluster\",\n",
        "    category_orders={\"dayofweek\": [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]},\n",
        "    title=\"Consumo por día de la semana (agrupado por tema)\",\n",
        "    barmode=\"overlay\",\n",
        "    color_discrete_sequence=px.colors.qualitative.Bold\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    template=\"plotly_white\",\n",
        "    xaxis_title=\"Día de la semana\",\n",
        "    yaxis_title=\"Cantidad de videos vistos\",\n",
        "    width=950,\n",
        "    height=500,\n",
        "    legend_title_text=\"Cluster temático\"\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "# ============================================================\n",
        "# Mapa de calor hora × día\n",
        "# ============================================================\n",
        "df_heat = (\n",
        "    df_embed.groupby([\"dayofweek\", \"hour\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"count\")\n",
        "    .pivot(index=\"dayofweek\", columns=\"hour\", values=\"count\")\n",
        "    .reindex([\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"])\n",
        ")\n",
        "\n",
        "fig = px.imshow(\n",
        "    df_heat,\n",
        "    color_continuous_scale=\"Turbo\",\n",
        "    title=\"Mapa de calor — Actividad por día y hora\",\n",
        "    labels=dict(x=\"Hora del día\", y=\"Día de la semana\", color=\"Vistas\")\n",
        ")\n",
        "fig.update_layout(width=950, height=500, template=\"plotly_white\")\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Mapa de calor hora × cluster\n",
        "# ============================================================\n",
        "# --- Agrupación: número de vistas por cluster y hora ---\n",
        "df_cluster_hour = (\n",
        "    df_embed.groupby([\"cluster\", \"hour\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"count\")\n",
        ")\n",
        "\n",
        "# --- Normalizar por cluster (opcional: proporción dentro de cada cluster) ---\n",
        "df_cluster_hour[\"pct\"] = (\n",
        "    df_cluster_hour.groupby(\"cluster\")[\"count\"]\n",
        "    .transform(lambda x: x / x.sum())\n",
        ")\n",
        "\n",
        "# --- Pivotear para matriz ---\n",
        "heat_data = df_cluster_hour.pivot(index=\"cluster\", columns=\"hour\", values=\"pct\").fillna(0)\n",
        "\n",
        "# ============================================================\n",
        "# Visualización con Plotly\n",
        "# ============================================================\n",
        "fig = px.imshow(\n",
        "    heat_data,\n",
        "    color_continuous_scale=\"Viridis\",  # paleta agradable y legible\n",
        "    title=\"Patrón horario de consumo por cluster temático\",\n",
        "    labels=dict(x=\"Hora del día\", y=\"Cluster temático\", color=\"Proporción dentro del cluster\"),\n",
        "    aspect=\"auto\"\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    template=\"plotly_white\",\n",
        "    width=950,\n",
        "    height=500,\n",
        "    xaxis_title=\"Hora del día\",\n",
        "    yaxis_title=\"Cluster temático\",\n",
        "    coloraxis_colorbar=dict(\n",
        "        title=\"Proporción\",\n",
        "        tickformat=\".0%\",\n",
        "        len=0.7\n",
        "    ),\n",
        "    font=dict(size=13),\n",
        "    title=dict(x=0.05, xanchor=\"left\", font=dict(size=18)),\n",
        "    margin=dict(l=60, r=20, t=60, b=60)\n",
        ")\n",
        "\n",
        "fig.update_xaxes(dtick=1, tick0=0, showgrid=False)\n",
        "fig.update_yaxes(type=\"category\", showgrid=False)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "n8HtX0KgqXtQ"
      },
      "id": "n8HtX0KgqXtQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🕒 1️⃣ Distribución horaria de visualizaciones por cluster temático\n",
        "\n",
        "📊 Lo que se observa:\n",
        "\n",
        "Hay picos de consumo entre las 14:00 y las 22:00, especialmente hacia la tarde-noche.\n",
        "\n",
        "Entre las 00:00 y las 05:00 el consumo baja considerablemente, con un pequeño repunte nocturno.\n",
        "\n",
        "Los clusters musicales (7, 1, 4) y el de educación (5) dominan en la franja de tarde-noche.\n",
        "\n",
        "Un pico anómalo alrededor de las 18:00 podría reflejar un horario de descanso o una rutina específica (por ejemplo, escuchar música o mirar contenido educativo después del trabajo/estudio).\n",
        "\n",
        "🎯 Interpretación:\n",
        "\n",
        "Este patrón muestra una rutina bastante estable, con una clara preferencia por el consumo en horario vespertino.\n",
        "\n",
        "No se detecta un comportamiento fuerte de doomscrolling nocturno (es decir, no hay sobreconsumo de madrugada).\n",
        "\n",
        "La concentración entre las 18:00–22:00 puede indicar una ventana de ocio personal, donde el algoritmo refuerza temas de entretenimiento y música.\n",
        "\n",
        "📅 2️⃣ Consumo por día de la semana (agrupado por tema)\n",
        "\n",
        "📊 Lo que se observa:\n",
        "\n",
        "El consumo es constante de lunes a viernes, con un leve pico el martes, y una caída notable el sábado y domingo.\n",
        "\n",
        "Durante los días laborales, los clusters musicales y educativos son los más dominantes.\n",
        "\n",
        "El fin de semana, aunque baja el volumen total, el consumo sigue siendo principalmente de música y entretenimiento.\n",
        "\n",
        "🎯 Interpretación:\n",
        "\n",
        "Indica un patrón de consumo asociado a rutina laboral o académica, donde se consume contenido como acompañamiento o distracción durante la semana.\n",
        "\n",
        "El descenso del fin de semana podría reflejar una desconexión digital parcial o cambio de plataforma (por ejemplo, streaming, series, actividades offline).\n",
        "\n",
        "La estabilidad entre lunes y viernes sugiere que el algoritmo ha aprendido tus horas y días típicos de conexión, reforzando recomendaciones afines en esas franjas.\n",
        "\n",
        "🔥 3️⃣ Mapa de calor — Actividad por día y hora\n",
        "\n",
        "📊 Lo que se observa:\n",
        "\n",
        "Las zonas más intensas (colores rojos/naranjas) se concentran entre las 14:00 y las 22:00 durante lunes a viernes.\n",
        "\n",
        "Se nota actividad baja entre 8:00 y 12:00, probablemente horas de trabajo o estudio.\n",
        "\n",
        "El sábado y domingo muestran menos actividad general, con un patrón más difuso.\n",
        "\n",
        "Los picos nocturnos (después de las 23:00) son esporádicos, no sistemáticos.\n",
        "\n",
        "🎯 Interpretación:\n",
        "\n",
        "La matriz refuerza la conclusión de que tu consumo sigue una estructura regular, no caótica.\n",
        "\n",
        "No hay evidencia clara de doomscrolling, ya que no existe concentración sistemática en la madrugada.\n",
        "\n",
        "Sin embargo, la franja 18:00–22:00 muestra un “nicho de recomendación” muy activo, donde los algoritmos probablemente te sirven contenido más emocional o de entretenimiento (música, gaming, shows).\n",
        "\n",
        "| Aspecto                 | Observación              | Interpretación                                          |\n",
        "| ----------------------- | ------------------------ | ------------------------------------------------------- |\n",
        "| ⏰ **Horario**           | Picos 18:00–22:00        | Rutina de ocio vespertina, sin sobreexposición nocturna |\n",
        "| 📅 **Días activos**     | Lunes–viernes            | Consumo ligado a rutina laboral/estudio                 |\n",
        "| 🎵 **Temas dominantes** | Música y entretenimiento | El algoritmo refuerza contenido relajante y repetitivo  |\n",
        "| 💤 **Doomscrolling**    | No evidente              | Sin patrón de consumo nocturno excesivo                 |\n",
        "\n",
        "\n",
        "Tu patrón de consumo revela hábitos consistentes y temáticamente estables. El algoritmo parece haber aprendido tu “ventana de atención” principal (tardes-noches entre semana), reforzando contenido musical y de ocio.\n",
        "No se detecta un patrón de doomscrolling prolongado, pero sí una zona de concentración horaria donde podrías explorar mayor variedad temática si quisieras evitar reforzar hábitos algorítmicos repetitivos."
      ],
      "metadata": {
        "id": "QBnFfUMA92fi"
      },
      "id": "QBnFfUMA92fi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.4 Diversidad temática en el tiempo"
      ],
      "metadata": {
        "id": "AcD8rCda3CrC"
      },
      "id": "AcD8rCda3CrC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos medir si la diversidad (entropía) que calculamos anteriormente, ha crecido o disminuido a lo largo del tiempo.\n",
        "Interpretación:\n",
        "\n",
        "* Entropía sube → más diversidad, menos burbuja.\n",
        "* Entropía baja → concentración en pocos temas (burbuja reforzada).\n",
        "\n",
        "\n",
        "| Valor de entropía | Interpretación                                            | Implicación                                |\n",
        "| ----------------- | --------------------------------------------------------- | ------------------------------------------ |\n",
        "| **Alta (↑)**      | Tu consumo está distribuido entre varios temas o clusters | Más exploración, menor sesgo               |\n",
        "| **Baja (↓)**      | La mayoría de tus vistas se concentran en pocos temas     | Menor diversidad, posible burbuja temática |\n"
      ],
      "metadata": {
        "id": "wGs9FR1dqXzz"
      },
      "id": "wGs9FR1dqXzz"
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Cálculo de entropía mensual\n",
        "# ============================================================\n",
        "df_embed[\"timestamp\"] = pd.to_datetime(df_embed[\"timestamp\"], errors=\"coerce\")\n",
        "\n",
        "df_div = (\n",
        "    df_embed\n",
        "    .assign(month=df_embed[\"timestamp\"].dt.to_period(\"M\").astype(str))\n",
        "    .groupby(\"month\")[\"cluster\"]\n",
        "    .apply(lambda x: entropy(x.value_counts(normalize=True)))\n",
        "    .reset_index(name=\"entropy\")\n",
        "    .sort_values(\"month\")\n",
        ")\n",
        "\n",
        "print(f\"Se calcularon {len(df_div)} periodos mensuales con valores de entropía.\")\n",
        "\n",
        "# ============================================================\n",
        "# Visualización temporal\n",
        "# ============================================================\n",
        "fig = px.line(\n",
        "    df_div,\n",
        "    x=\"month\",\n",
        "    y=\"entropy\",\n",
        "    title=\"Evolución de la diversidad temática (entropía por mes)\",\n",
        "    markers=True,\n",
        "    line_shape=\"spline\",\n",
        "    color_discrete_sequence=[\"#1f77b4\"]\n",
        ")\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Mes\",\n",
        "    yaxis_title=\"Entropía (diversidad temática)\",\n",
        "    template=\"plotly_white\",\n",
        "    width=950,\n",
        "    height=500\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "EI7011wDqgy5"
      },
      "id": "EI7011wDqgy5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Comportamiento general**\n",
        "La entropía promedio se mantiene en torno a 1.6–1.8, lo que indica una diversidad moderada: no está encerrado en un solo tipo de contenido, pero sí existen preferencias marcadas.\n",
        "\n",
        "Hay una alta variabilidad mensual, con picos y valles frecuentes → esto refleja etapas de exploración seguidas por periodos de consumo concentrado. Por ejemplo \"focos\" en temas especificos.\n",
        "\n",
        "\n",
        "Periodos clave observables:\n",
        "\n",
        "| Periodo       | Entropía                                 | Interpretación                                                                                                 |\n",
        "| ------------- | ---------------------------------------- | -------------------------------------------------------------------------------------------------------------- |\n",
        "| **2018–2019** | En ascenso (hasta ~2.0)                  | Fase de exploración inicial, consumo variado entre varios temas.                                               |\n",
        "| **2020–2021** | Fluctuante, picos y caídas leves         | Consolidación de hábitos: algunos temas dominan temporalmente (posible inicio de burbuja musical o educativa). |\n",
        "| **2022**      | Ligera caída (~1.4–1.5)                  | Concentración en menos temas → probablemente una preferencia más establecida (ej. música o entretenimiento).   |\n",
        "| **2023–2024** | Recuperación de diversidad (~1.8–2.0)    | Retorno a exploración, aparición de nuevos clusters o intereses.                                               |\n",
        "| **2025**      | Descenso abrupto (<1.0 en algunos meses) | Fuerte concentración en pocos temas — posible sesgo de recomendación o repetición temática.                    |\n",
        "\n",
        "Mi consumo ha oscilado entre etapas de exploración y de concentración.\n",
        "En los últimos meses, la diversidad temática disminuyó, lo que sugiere una “burbuja\" reforzada por el algoritmo, tras años de variedad más alta. Esto producto a que recientemente utilizo YT para videos del mismo cluster temático."
      ],
      "metadata": {
        "id": "Sxjr7yyi-ntP"
      },
      "id": "Sxjr7yyi-ntP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 10. Conclusiones y trabajo futuro"
      ],
      "metadata": {
        "id": "mc1-vDg0EKgH"
      },
      "id": "mc1-vDg0EKgH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.1 Conclusiones principales\n",
        "\n",
        "1. **Tres sistemas de recomendación fueron comparados exitosamente**:  \n",
        "   - *Popularidad (Baseline)* — basado solo en la frecuencia de vistas.  \n",
        "   - *Contenido (Embeddings)* — utiliza similitud semántica entre videos mediante `content_vec`.  \n",
        "   - *Híbrido Contextual* — combina similitud de contenido con contexto temporal, categórico y de interacción.  \n",
        "\n",
        "2. **El modelo híbrido obtuvo el mejor equilibrio global** entre precisión, cobertura y diversidad.  \n",
        "   - Aunque su `Precision@10` es baja (≈1%), mantiene la mejor `Recall@10` y una **diversidad superior al modelo de popularidad**.  \n",
        "   - Los boosts contextuales (hora, día, canal) ayudaron a mejorar la personalización sin sacrificar cobertura.\n",
        "\n",
        "3. **El análisis temático (K-Means + t-SNE)** reveló **8 clusters de contenido** principales, que representan grupos coherentes.\n",
        "\n",
        "4. **La diversidad temática (entropía)** varía a lo largo del tiempo:  \n",
        "   - **Alta entre 2018–2020 y 2023–2024**, donde el consumo fue variado (entre temáticas).  \n",
        "   - **Baja entre 2021–2022 y 2025**, dominada por los clusters especificos → **signo de burbuja de contenido**.  \n",
        "   - Esto sugiere que el algoritmo de YouTube refuerza los hábitos cuando el usuario concentra su atención en pocos géneros.\n",
        "\n",
        "5. **Patrones de horario y hábito:**  \n",
        "   - Mayor actividad nocturna y entre semana (especialmente martes–viernes).  \n",
        "   - Concentración de ciertos temas en franjas horarias, indicios de **sesgo horario**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "UU-ZElbTEv1N"
      },
      "id": "UU-ZElbTEv1N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 10.2 Limitaciones\n",
        "\n",
        "- **Datos individuales:** el análisis proviene de un único usuario, lo que limita la generalización.  \n",
        "- **Ausencia de señales explícitas de feedback (likes, tiempo de reproducción real, watch_ratio)**  \n",
        "- **Sin evaluación de ranking o métricas NDCG** — se midieron solo `Precision@k`, `Recall@k`, `Coverage` y `Diversity`.  \n",
        "- **Temporalidad parcial:** las métricas no incorporan predicción secuencial de comportamiento futuro.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "-z4flVFE9iSm"
      },
      "id": "-z4flVFE9iSm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 10.3 Trabajo futuro\n",
        "\n",
        "1. **Incorporar un modelo colaborativo (user-item o matrix factorization)**  \n",
        "   - Permitiría comparar la personalización basada en comunidad frente a la basada en contenido individual.  \n",
        "\n",
        "2. **Usar embeddings preentrenados más potentes** (ej. `sentence-transformers`, `YouTube8M embeddings`)  \n",
        "   - Mejoraría la semántica del `content_vec` y la precisión del recomendador.\n",
        "\n",
        "3. **Evaluar métricas adicionales:**  \n",
        "   - `NDCG@k`, `MAP@k`, `Serendipity`, `Novelty` y `Fairness`.  \n",
        "   - Analizar el balance entre exploración y explotación.\n",
        "\n",
        "4. **Analizar evolución de la burbuja algorítmica longitudinalmente**  \n",
        "   - Medir cómo cambia la entropía temática después de cada periodo de alta concentración.  \n",
        "   - Comparar si el usuario “rompe” la burbuja con nuevos temas o si el algoritmo refuerza lo ya conocido.\n",
        "\n",
        "5. **Ampliar el enfoque ético y de privacidad:**  \n",
        "   - Reflexionar sobre el impacto de los sistemas de recomendación en el bienestar digital y la autonomía del usuario.  \n",
        "   - Proponer mecanismos de transparencia y control sobre las recomendaciones.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "a8491mie9mIA"
      },
      "id": "a8491mie9mIA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 10.4 Conclusión general\n",
        "\n",
        "> El análisis demuestra cómo un sistema de recomendación puede pasar de reflejar la curiosidad del usuario a reforzar hábitos estrechos de consumo.  \n",
        ">  \n",
        "> Medir la **diversidad temática y temporal** proporciona una forma cuantitativa de detectar **burbujas algorítmicas**, abriendo el camino hacia sistemas más transparentes y equilibrados.\n",
        "\n"
      ],
      "metadata": {
        "id": "JQyamaNn92Dn"
      },
      "id": "JQyamaNn92Dn"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KD_g7GDneoxo"
      },
      "id": "KD_g7GDneoxo"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}